{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdze1nPE1ts7xV11R6mmgf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vilsonrodrigues/youtube-retrieval-qa/blob/main/notebooks/YoutubeRetrievalQA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai youtube-transcript-api faiss-cpu tiktoken"
      ],
      "metadata": {
        "id": "u0IcuZXLbq_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = 'sk-...'"
      ],
      "metadata": {
        "id": "S_xweI_RguYu"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Document Load "
      ],
      "metadata": {
        "id": "Bz8qH1CcietR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import YoutubeLoader"
      ],
      "metadata": {
        "id": "0EKxpf5hcKqn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## load transcripts\n",
        "video_url = 'https://www.youtube.com/watch?v=ibNCc74ni1c'\n",
        "loader = YoutubeLoader.from_youtube_url(video_url, add_video_info=False)\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "YJGgDiaCdQWm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhVz4ampdk5K",
        "outputId": "4bc7ae39-468d-49df-cd6c-0c95eaedfbce"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"The Washington Post Newsroom delivers breaking events around the world as they happen unrivaled reporting from the journalists you've come to trust to get the facts fast and meet the challenges of today head on get the news that matters most with a special offer by visiting washingtonpost.com watch subscribing unlocks instant access bringing you the post's award-winning coverage Anytime Anyplace because democracy dies in darkness thank you [Music] artificial intelligence comes to Congress as the head of one of the leading AI companies testifies before the Senate today Sam Altman is the head of open AI the company behind the chat bot chat to BT well today's hearing comes as Congress and frankly the world wrestles with the power and potential of artificial intelligence welcome to this special report from The Newsroom of the Washington Post I'm Libby Casey in addition to Sam Altman members of a senate subcommittee will also hear from an IBM vice president and an AI researcher joining me here in the studio James Homan opinion columnist and on Capitol Hill Rhonda Colvin senior political correspondent welcome to you both Rhonda what got us to today and what do senators want to hear about well what I'm hearing about the design of this hearing is that Senators want to get ahead of this technology and figure out ways of regulating Ai and this is going to be a first step it's a technology that is of concern to many Americans but there are also some merits that Senators say they want to look into as well so that is uh the reason why this is happening right now there is a sense of urgency on Capitol Hill to get ahead of this technology instead of being behind we've seen other Tech hearings where it often looks like members don't quite understand what's going on but this is an attempt to get lawmakers briefed on the technology of AI I spoke to a committee aide yesterday who kind of gave me a lay of the land of what to expect they said that this is likely going to be a very friendly hearing the Witnesses are all coming on their own they were not subpoenaed they want to participate in this and so lawmakers are likely going to give them a break for that and ask questions based on being educated and finding out more about how they can regulate the other thing that the committee aide said is you might might expect a very robust discussion among the panelists themselves you mentioned Sam Altman he is of course an industry leader in AI but also on the panel is an Emeritus Professor from NYU who actually has been slightly critical he's talked about the merits but he's also researched and been a little critical and asked the AI industry to slow down a little bit so that the world can catch up to this technology and more proof that AI is becoming a topic of conversation here on Capitol Hill at the very same time 10 a.m the Senate Homeland Security is also going to have a hearing on AI they're going to be looking at the role of AI in the government great Point Rhonda you know James there is a lot of uh interest right now on Capitol Hill in this technology how significant is this moment in Ai and what's your feeling about congress's preparedness and ability to meet this moment we're at the dawn of a new era uh you know we feel like we've gone through so much disruption and we're about to go through more where it ends we don't know even someone like Sam Altman will be the first to say we don't know how this ends and that is why you need guard rails that you need to think through the and wrestle with grapple with the big questions about how this could change society elections the jobs so much else so I think a lot of Congress knows and understands that they're not fully equipped that there's really not currently an apparatus within our government to monitor AI to audit AI to certify it and these are sort of good corporate actors who are trying to be responsible and do the right thing I think today is going to be yeah when you talk about good corporate actors there's a real question of whether or not the companies will decide how they compete against each other are they trying to win a race for money are they trying to win a waste for profit and Innovation or I mean they have a different motivation than lawmakers exactly and that's why it's important that you know congress not just defer to them this is sort of the honeymoon period you know right now we're dazzled by chat GPT it's fun to play around with it's impressive we're sort of vaguely aware of some of the dangers and the risks but this is really I think going to be viewed as a watershed day in the history of kind of the Silicon Valley Washington relationship as it relates to AI because I think this is you know these are people who are going to be candid about the the pluses and the minuses on this panel today this is actually some of the most serious members of the U.S Senate and both parties are on this panel and are in intent on sort of fact-finding and understanding the issue rather than just scoring political points and sound bites I think this is going to be a hugely fascinating hearing that really will lay the groundwork for potentially real bipartisan action uh on regulation new law uh you know but this is happening against the backdrop of I should say a few weeks ago Vladimir Putin said whoever controls AI will control the world Xi Jinping has made similar statements and so this isn't happening in a vacuum this is happening against the geopolitical backdrop of uh you know what war in Ukraine in which there are new technologies that are being deployed many of which we're not even aware of and China uh eager to out-compete us and to LeapFrog the United States on this hugely disruptive technology of the future so Rhonda let's talk about What legislation could look like and feel like and what members of Congress are thinking about well I should point out that today is a first step to any sort of legislation it this hearing is not based on any existing proposals that is why lawmakers want to have this as first in uh potentially a series of hearings on AI from this committee and then draft legislation that's uh one what one of the aides told me is the design the one of the current proposals that that might give an indication of where Congress might go on AI regulation is one that's been circulated by Chuck Schumer the majority uh leader in the Senate he last month circulated a draft or a framework that would try to put some guard rails around AI specifically have independent researchers look at any uh growing AI Technologies and examine them before their launch or before there were updates it's sort of designed to kind of slow down and give the government a chance to look at ways to regulate AI because it's such a fast-paced industry it's you know there's new AI all the time but one of the open questions for any legislation right now is how are they going to define AI it's so big we're already using you know components of AI in our daily work whether it be emails that are Auto filled or if you're you're talking to Siri or Alexa AI is already very present in our life but right now Congress is looking at ways to build at least a simple framework in order to get that on the floor and get that pass and I guess if you look at it the fact that the majority leader is sort of spearheading this that does say a lot because he of course determines the schedule in the Senate he determines what bills might get some time so that is an important thing to note that the majority leader himself is the one spearheading AI regulation right now and Chuck Schumer has said this is going to be a bipartisan issue James how does that actually play out though the devil's always in the details Elon Musk not exactly a favorite of Democrats right now met with Chuck Schumer last month on Capitol Hill to talk about these issues musk was a signatory on better for that was organized by something called the future of Life foundation with all these big name tech people calling for basically a pause in artificial intelligence research uh you're right to your point a few minutes ago Libby which is that you you know that you don't want to get in a position where corporations are sort of dictating what the rules are so that they basically lock it in so that only a few big players like Microsoft Google meta can control the space and it makes it hard for startups to get in because there are so many rules and laws that were sort of designed by the big players so you have to be mindful of that there's kind of a blueprint that's circulating on the hill for what an AI Bill of Rights might look like and some things would be much easier to get bipartisan support behind than others the the big thing is that there's bipartisan support for requiring that a chat bot tell you that you're talking to a chatbot so that you know if you're talking with someone that you understand that it's it's being generated by a computer it's not a real human that you're interacting with the second big thing that I think there's widespread support for is Banning algorithm discrimination uh you know one of the the problems is we obviously have a lot of good laws to prevent discrimination on the basis of race gender Etc but a machine might say oh this kind of person doesn't pay back their loans we're going to deny loans to everyone who has the same demographic profile as this person and you could quickly end up with with really discriminatory outcomes and so to somehow make it so that you know these algorithms aren't making for example loan decisions then it gets a little hairier uh you know data privacy they obviously haven't been able to agree on in other contexts uh the uh auditing transparency those kinds of things become harder but the the top line that's where you could see movement spring into the conversation Cristiano Lima who is outside the hearing room he'll be covering that today Cristiano is a tech newsletter reporter and the author of the technology 202 which focuses on the intersection of politics and policy Cristiano let's talk about what your expectations are for this hearing today yeah absolutely thank you for having me I think it's going to be a real uh grab bag that's really going to run the gamut I mean as I was mentioned this is a hearing broadly on oversight and regulation of AI there's not a topical Focus per se so we're going to see lawmakers raise issues around Ai and privacy Ai and misinformation how uh chat GPT and tools like it you know scrape up a lot of data and what that might mean for intellectual property some of the Senators I spoke to on the panel said that you know they're keeping an eye on the extent to which the technology Giants might be able to sort of corner the market including you know Microsoft's partnership with openai and so I but I do think that it's going to be a less combative hearing than we've seen in the past with tech CEOs a number of the lawmakers talked about this being an educational hearing that would inform legislation and generally did not seem to suggest that it would be the type of grilling session that we've seen with the likes of The Tick Tock CEO earlier this year for example what are members of Congress wanting to hear from Sam Altman and the other panelists I mean you know it sounds like from your reporting in Rhonda's reporting that this is like a learning opportunity and a chance for conversation what do they want to hear right well certainly the focus is on what checks should be put in place and I think that's a discussion that's still very much in the preliminary stages on Capitol Hill um as you guys alluded to Senator Schumer has been circulating uh potential framework around this but that's still a long ways from being legislative texts there have been a number of proposals that lawmakers have kicked around for years including on issues like data privacy but those have not um you know gained significant momentum enough to become laws at this point and so I think lawmakers are really trying to set their feet and figure out which issues to prioritize when it comes to how to draft legislation and you know a number of them said that they're looking for input in particular about you know how to approach AI regulation in a way that both uh uphold the American values of openness and Liberty on the web while also not um you know following the Playbook of China which has been more restrictive in its approach you've reported on the conversations and legislation happening in Europe right now can you give us a contrast to how they're grappling with regulating AI right so just like on a number of other Tech issues Europe is significantly far ahead of the U.S when it comes to setting rules of the road for AI you know Europe beats the US to the punch in terms of setting a data privacy protections they are working on uh an AI uh code of conduct so to speak uh to to impose regulations on on not only you know generative AI like chat GPT and similar tools but also some more targeted uses like how iei is used in education or uh in National Security and so certainly Europe is ahead of the game uh and I think lawmakers in the US are aware of that and are hoping that today will be a big step towards catching up you know you and James had both talked about the potential for companies to you know try to take control of this and lead a little bit to dominate the market but beyond dominating the market there's really a soul searching question of just how much control the companies that are creating this technology should have versus the people who are users of it sometimes victims of it potentially so how is Congress thinking about this moment of letting the companies lead versus leading the companies and trying to create like get way ahead of it and create framework instead of just having this you know Christiano this piecemeal approach to to taking bytes of legislation right I mean I think lawmakers are are certainly wary of letting some of the largest tech companies in the U.S dictate the terms of legislation to them uh you know there have been efforts for year to pass rules around as I mentioned data privacy but also competition and you know issues around social media and the harms that are potentially posed by that um and so I think there they're certainly aware of that Prospect um but you know from from the members that I spoke to they seem very eager to hear what Sam Altman has to say as you know someone that's coming from more of an upstart in the industry that's causing disruption at the moment all right Christiano Lima author of uh the technology 202 here at the Washington Post thank you so much for talking with us and thanks for covering that hearing let's go back to Rhonda you know Rhonda Cristiano has written that chat GPT really triggered an arms race in the tech industry that's his writing there so what will it be like for these lawmakers to hear from Sam Altman himself someone who can talk about that technology in particular well I think they're looking looking at this hearing and the fact that he is coming on a voluntary basis as a win right now that's why they're using this time uh to ask him the questions because you know none of them are experts there aren't many computer scientists on Capitol Hill and they want to explore what he has to say he probably is best suited to give the type of information that they're looking for right now in terms of education but the point that's been made a few times right now from you and James as well is will they allow what he's saying to determine exactly what they're going to do when it comes to regulation is he going to be driving that and I think that's why the other panelists the other Witnesses who are going to be testifying today were they play a role because there are they are going to be able to give some criticism especially the professor who has asked the AI industry to slow down a little bit in order for the world to catch up so I think to Cristiano's Point as well that this might be a little bit of a grab bag it won't be very contentious but it will be running the gamut of different types of questions I would also expect these lawmakers to ask questions about election security you know experts are talking about how 2024 is going to be a very interesting case test right now in terms of how AI is used when elections happen a lot of these lawmakers who might be up for re-election may be targeted through different AI measures and that's of concern so I'm also interested to see how that plays in this hearing James let's talk about chat GPT because it seems like it really did wake a lot of people up to the potential of this technology but also where things are at so how does it work just take us through the basics if someone hasn't played with it yet yeah totally and it is worth playing with I mean it's fascinating so GPT is actually an acronym it stands for chat generative pre-training Transformer essentially it's a large language learning model where you set up a computer and you have it read basically everything that's on the internet that you can and collect and look for patterns and connections and you know it it is basically teaching itself uh but they're setting they're giving it material they're giving it uh you know every Washington Post story that's ever been published and pulling it in uh and so the machine is learning this is what a Washington Post story sounds like and you can actually say in chat GPT write a uh write this in the style of a Washington Post editorial and it will put it out in sort of the voice of the editorial board it's it it I think that's sort of what woke people up and a lot of this has been out there but sort of kept quiet I mean it requires huge computational power it costs hundreds of millions of dollars just to get the technology together to be able to do this meta had something but decided not to put it out uh everyone had sort of been doing this chat GPT which is largely funded by Microsoft and open Ai and this sort of non-profit slash capped profit unique hybrid sort of setup they put theirs out there and all of a sudden it it I think shocked these other companies and so there's the arms race we've been talking about but there's also the a lot of this has been going on behind the scenes and now companies are eager to not be kind of not lose the first mover Advantage uh and so we're realizing a lot of this work has been going on pretty quietly but these computers are capable of quite a lot well joining us now from San Francisco Garrett divink Tech reporter covering Google algorithms and AI so Garrett welcome thanks for getting up so early for us tell us about Sam Altman you know he's an interesting guy he's someone who was very well known in the valley but actually not for AI or running open AI for years he ran Y combinator which is sort of probably the the biggest or most important or most influential uh startup incubator so it's kind of a venture capital firm that doesn't just in advance invest in startups but sort of takes them on uh brings in a bunch of experts other Business Leaders and and teaches them up over sort of a few months to a year about you know how to grow and so it's a very prestigious thing if you're a young founder to get accepted into Y combinator and for years Sam Altman worked there then he ran it and he made investments in companies on his own he was known as someone who kind of had a lot of big ideas about you know how technology would impact the world so he was looking into Universal basic income which is you know when you give everyone in a society a set amount of money because potentially AI has taken away all their jobs uh he put a lot of interest interest in Research into urban planning and new ways to design cities and that kind of thing and so that's sort of where openai came out of it was one of his uh projects that he was working on as you know oh this is an interesting technology that might change the future let's put some research into it and you know that's where how we find ourselves where we are today Garrett in addition to attending this hearing today and testifying as our panelists have pointed out willingly he hasn't been subpoenaed he also met with members of Congress last night for a dinner so what is he trying to achieve by having both these very public moments of conversation with members of Congress but also uh you know having more of that informal conversational just talking things through with them one might call that like the charm offensive right what is he trying to achieve yeah and I think it's important to put you know the hearing today that dinner in sort of a broader context for the in the past month Sam Altman has been flying all over the world in a private jet I have to assume meeting with world leaders politicians he was in Canada last week so you have to look at this meeting as sort of you know it's not that he's just focused on the US he is focused globally on trying to set a narrative around artificial intelligence which is that the technology is powerful that the technology is potentially dangerous but also that we humans specifically people like him and the companies in charge of it and Shepherd us along this path without anything catastrophic going and so I think he's trying to calm people down he's trying to have those conversations about some of these fears that that people are expressing both about you know things that we see happening today already when we look at biases when we look at misinformation things that might happen in the future such as job displacement and some of those really wacky out their fears about you know AI becoming sentient and taking over the world you know he's obviously getting questions about that and so I think he's really trying to swoop in and say hey I know y'all are talking about this but I'm sort of the calm reasoned expert you should listen to me okay Garrett you call it wacky um but let's talk about what some of the actual fears are with this technology everything from displacing workers to you know creating something like the Pandora's Box the genie out of the bottle whatever metaphor you want to use something that can ultimately be controlled yeah I mean and those are things that some very smart people are talking about I mean I think it's really important though to say that there's other really smart people who say that that is you know wacky that it it just only serves the companies themselves right I mean if you are selling chat gbt or you are known as you know the leader in AI technology you kind of want the world to think that this technology is magical that it is world changing that it will disrupt jobs that it will you know change the future um because then your investors say huh I want to give you money and people say huh I want to be in on that I want to learn about it you know if in the same way we don't quite have self-driving cars yet after you know 15 years and billions and billions of dollars of venture capital investment now we'll probably get there at some point but all the promises about you know buy 2022 2023 we would all be driving around in self-private cars obviously if not come to fruition and a lot of that Venture Capital Money That's gone into it has just you know gone into companies that are now bankrupt or have closed up shop or sold to other companies and so you know the AI Skeptics are saying we might be seeing a similar sort of trend here where the people who stand most to gain are the ones who are kind of Fanning the Flames of these really you know optimistic scenarios or maybe pessimistic depending on how you look at it and so I mean I wouldn't say that Sam almond is one of the people who says that AI will it you know soon become sentient I think he's quite grounded he talks more about um dictators or authoritarian States or you know even States run by democratic governments using it against their own people um you know using to supercharge surveillance you know we already live in a world where we're constantly being you know potentially watched through all sorts of cameras and social media what if you had AI technology that could you know use all that data sift through it on its own and you know give police or you know dictators sort of an ability to kind of pinpoint and target people much more easily and so those are more than concerns that he's talking about and I think those are concerns shared by a lot of people across sort of this ideological Spectrum when it comes to AI all right Gary stay with us I want to bring James into this conversation so the importance of having Sam Altman on this panel along with the other two panelists how do they round each other out I think it's a it's a very good balance because Altman is very candid uh and he is open he acknowledges the Technology's shortcomings the potential risks and dangers he's not just there to talk about how cool this tool that he built is the way that you know in the honeymoon era you would have seen a Mark Zuckerberg do uh and he's he's a futurist he's someone who really has thought very very deeply about the future of the planet and he's not just investing in this AI stuff he also has done uh a lot with trying to make humans live longer he's uh one of the startups he funds is about nuclear fusion uh and you know new energy sources uh he's a survivalist in some ways because he's alarmed about the the pitfalls of this technology so he's an interesting person who I think is going to be very candid and and actually respond to the questions instead of giving the speech he wants to give Rhonda Congress make sure it's it's dealing with this new technology and I don't want to create an adversarial analogy here but how are they fighting this battle and not fighting the last battle or the last war because Congress has had such a hard time dealing with the regulation of social media and other platforms that's right you might remember just two years ago Senator Blumenthal who chairs this subcommittee also chaired another subcommittee where he looked at section 230 and trying to protect Children online and we covered those hearings as well uh that's that is a great question when I don't think we have an answer to right now this hearing today is just going to be the start of more to come in fact uh staffers with the committee said that they already have a second one in mind related to AI but they want to see how today goes first before announcing that or moving forward on that so I think this is something that we're just going to continue to watch I know we're in the house side they too have been trying to highlight the merits as well as potential pitfalls of AI there was one lawmaker who Ted Lou Who is actually a computer Scientist by background he had AI write a law on how to regulate Ai and have that on the floor just to show an example of how powerful this tool is and how it could be used for good but also has some concerns you've also had house members who have had their opening statements and committee hearings written by AI so or four speeches written by AI so it is something that you see both Chambers trying to figure out which is always the first step but it is that question of what are they going to do with the information they received today or ongoing and further hearings Garrett let's turn that question to you how does congress not fight the last war and take this technology on its own and get past the problems they've had really achieving some bipartisan progress on other technology issues sort of the encouraging thing is that you know AI has been around for a while but this particular kind of Technology that's gotten everyone excited generative AI is quite new in terms of getting out in people's hands people actually you know being able to use it and at this point you know people are using it um and there are you know some signs here and there of some potential risk things going wrong but for the most part tools like chat GPT people haven't quite figured out exactly how they fit into life I mean we don't have a situation where millions of people have already lost their jobs because a product from openai or Microsoft or Google has taken it away most people are still figuring out okay how do I exactly use this the companies themselves are not making a lot of money off this yet it costs a tremendous amount of money to run in the background on on their Cloud servers and so they're just pouring money into this getting it out into people's hands hoping that some you know potential ideas for how to actually sell it and make money will come out of it and so we're at a much earlier stage in the conversation and sort of the the tech lifestyle than we are with social media and misinformation that you know we saw after 2016 when there was so much scrutiny criticism we had all these hearings about social media their effect on its effects on politics effect on society again the misinformation as well you know that was a decade after Facebook sort of became popularized right and so I think you know that's something that people are talking about now I think lawmakers they're trying to get ahead of this one before it sort of gets out of their hands James you've talked to us about what we may hear from Sam Altman talk to us about the other panelists and why they are relevant to this conversation today so we're going to hear from an executive at IBM IBM uh you know obviously International Business Machines the oldest school of the tech companies they were actually at the kind of the Forefront of a lot of this member Watson uh when it played Jeopardy got a lot of attention IBM has developed a lot of this the person who we're going to hear testify today their boss said just last week that IBM believes they could get rid of 7 800 jobs of the 26 000 customer-facing jobs that they have uh including human non-customer facing jobs including Human Resources uh that they think can be totally automated by this technology so the you know they're out there bragging about that uh and again friendly back and forth with members of Congress but I think IBM is going to have to explain the disruptive potential uh and how they see it for their own business versus you know everyone else's business IBM could make a lot of money advising companies on how to automate jobs so that they can lay off workers and have machines do them instead Rhonda who will you be watching for on this subcommittee today it's a Judiciary subcommittee that's focused on privacy technology and the law who will you be watching honestly I think the chair of the committee Senator Blumenthal is is one of the ones to watch just because he's sort of been at the Forefront in this in the Senate trying to highlight the harms of uh online security and This falls into that jurisdiction as well so as I mentioned earlier he was a part of the Senate team that wanted to develop rules to protect Children online uh when it came to Facebook or Instagram so he's pretty knowledgeable on this and has sort of been driving this conversation I would also look at someone his uh the ranking member the top Republican Josh Hawley he too has been signaling that he's very interested in figuring this out in a bipartisan way so both the chair and the ranking member are two to watch you do have some some members on here who have also been talking about AI for a while Senator Kris and the coons of Delaware who used to lead this committee he too has been talking about AI regulations for a while so I think when it comes to the Senate this group probably is well versed in and in this area I guess as best they can be but again AI is so big and it's growing by the day that it may be hard for senators to figure out you know what type of questions asked what to focus on and how to build legislation out of that so today is going to be very interesting in terms of that that we are going to hear a lot of different questions and that will also give us a glimpse of where these lawmakers might take any uh proposals James who do you want us to pay attention to on this committee well the two youngest members of the U.S Senate are on the committee uh Josh Hawley who Ronda was just mentioning who was at Stanford at the same time as Sam Altman they didn't know each other my understanding is but they were both there same era uh and John ossoff the Democratic senator from Georgia these are one on each side of the eye one on each side of the aisle these are are young people who understand Tech you know Assaf is sort of a digital native in some ways and I I'm I really struck looking at the list of the members of the subcommittee by how many sort of tech Skeptics there are uh you know traditionally Republicans were the party of business uh but some of the kind of the most populous skeptical of large corporations I'm thinking of Mike Lee Marsha Blackburn from Tennessee John Kennedy from Louisiana and of course Holly who wrote a whole book about uh getting the whole tech industry under control and has advocated legislation recently to ban social media for people under 18 and believes the government should have a muscular role so you might actually have a weird role reversal here where you know Blumenthal is is also skeptical and is it wants you know former State Attorney General all about regulating it but you think about people like Amy Klobuchar Chris Coons Alex Padilla they're going to be you know Alex pettius from California he represents the big tech companies uh the the the Democrats on the panel might actually be more receptive and amenable to letting the tech companies write the rules than the Republicans in this group so it's after 10 o'clock here on the east coast and we are awaiting images from this hearing let's go to it now let's see if we've got a live shot of the Senate Judiciary subcommittee we're just getting some of the technology sorted out between the Senate and us and as soon as we get that fully up we will bring you this live it's coverage from The Washington Post I want to thank all of my guests you can see there the chair Richard Blumenthal of Connecticut we're just working out the audio problem here thanks so much to everyone for joining us today proliferation of and the deepening of societal inequalities we have seen how algorithmic biases can perpetuate discrimination and Prejudice and how the lack of transparency can undermine public Trust this is not the future we want if you were listening from home you might have thought that voice was mine and the words from me but in fact that voice was not mine the words were not mine and the audio was an AI voice cloning software trained on my floor speeches the remarks were written by chat gbt when it was asked how I would open this hearing and you heard just now the result I asked chat GPT why did you pick those themes and that content and it answered and I'm quoting Blumenthal has a strong record in advocating for consumer protection and civil rights he has been vocal about issues such as data privacy and the potential for discrimination in algorithmic decision making therefore the statement emphasizes these aspects Mr Altman I appreciate chat gpt's endorsement in all seriousness this apparent reasoning is pretty impressive I am sure that we'll look back in a decade and view chat GPT and gpt4 like we do the first cell phone those big clunky things that we used to carry around but we recognize that we are on the verge really of a new era the audio and my playing it may strike you as curious or humorous but what reverberated in my mind was what if I had asked it and what if it had provided an endorsement of Ukraine surrendering or Vladimir Putin's leadership that would have been really frightening and the prospect is more than a little scary to use the word Mr Altman you have used yourself and I think you have been very constructive in calling attention to the pitfalls as well as the promise and that's the reason why we wanted you to be here today and we thank you and our other Witnesses for joining us for several months now the public has been fascinated with GPT dally and other AI tools these examples like the homework done by chat GPT or the Articles and op-eds that it can write feel like novelties but the underlying advancement of this era are more than just research experiments they are no longer fantasies of Science Fiction they are real and present the promises of during cancer or developing new understandings of physics and biology or modeling climate and weather all very encouraging and hopeful but we also know the potential Harms and we've seen them already weaponized disinformation housing discrimination harassment of women and impersonation fraud voice cloning uh deep fakes these are the potential risks despite the other rewards and for me perhaps the biggest nightmare is the looming new Industrial Revolution the displacement of millions of workers the loss of huge numbers of jobs the need to prepare for this new Industrial Revolution in skill training and relocation that may be required and already industry leaders are calling attention to those challenges to quote chat gbt this is not necessarily the future that we want we need to maximize the good over the bad Congress has a choice now we had the same Choice when we Face social media we failed to seize that moment the result is Predators on the internet toxic content exploiting children creating dangers for them and Senator Blackburn and I and others like Senator Durbin on the Judiciary Committee are trying to deal with it kids online safety act but Congress failed to meet the moment on social media now we have the obligation to do it on AI before the threats and the risks become real sensible safeguards are not in opposition to Innovation accountability is not a burden far from it they are the foundation of how we can move ahead while protecting public trust they are how we can lead the world in technology and science but also in promoting our Democratic Values otherwise in the absence of that trust I think we may well lose both these are sophisticated technology but there are basic expectations common in our law we can start with transparency AI companies ought to be required to test their systems disclose known risks and allow independent researcher access we can establish scorecards and nutrition labels to encourage competition based on safety and trustworthiness limitations on use there are places where the risk of AI is so extreme that we ought to impose restriction or even ban their use especially when it comes to commercial invasions of privacy for profit and decisions that affect people's livelihoods and of course accountability reliability when AI companies and their clients cause harm they should be held liable we should not repeat our past mistakes for example section 230 forcing companies to think ahead and be responsible for the ramifications of their business decisions can be the most powerful tool of all garbage in garbage out the principal still applies we ought to Beware of the garbage whether it's going into these platforms or coming out of them and the ideas that we develop in this hearing I think will provide a solid path forward I look forward to discussing them with you today and I will just finish on this note the AI industry doesn't have to wait for Congress I hope their ideas and feedback from this discussion and from the industry and voluntary action such as we've seen lacking in many social media platforms and the consequences have been huge so I'm hoping that we will elevate rather than have a race to the bottom and I think these hearings will be an important part of this conversation this one is only the first the ranking member and I have agreed there should be more and we're going to invite other industry leaders some have committed to come experts academics and the public we hope will participate and with that I will turn to the ranking member Senator Hawley thank you very much Mr chairman thanks to the witnesses for being here I appreciate that several of you had long Journeys to make in order to be here I appreciate you making the time I look forward to your testimony I want to thank Senator Blumenthal for convening this hearing for being a leader on this topic you know a year ago we couldn't have had this hearing because the technology that we're talking about had not burst into public Consciousness that gives us a sense I think of just how rapidly this technology that we're talking about today is changing and evolving and Transforming Our World right before our very eyes I was talking with someone just last night a researcher in the field of Psychiatry who was pointing out to me that the chat GPT and generative AI these large language models it's really like the invention of the internet in scale at least at least and potentially far far more significant than that we could be looking at one of the most significant technological innovations in human history and I think my question is what kind of an innovation is it going to be is it going to be like the printing press that diffused knowledge and power and learning widely across the landscape that empowered ordinary everyday individuals that led to Greater flourishing that led above all to Greater Liberty or is it going to be more like the atom bomb huge technological breakthrough but the consequences severe terrible continue to haunt us to this day I don't know the answer to that question I don't think any of us in the room know the answer to that question because I think the answer has not yet been written and to in a certain extent it's up to us here and to us as the American people to write the answer what kind of Technology will this be how will we use it to better Our Lives how will we use it to actually harness the power of technological innovation for the good of the American people for the liberty of the American people not for the power of the few you know I was I was reminded of the psychologist and writer Carl Young Who said at the beginning of the last century that our ability for technological innovation our capacity for technological revolution had far outpaced our ethical and moral ability to apply and harness the technology we developed that was a century ago I think the story of the 20th century largely bore him out and I just wonder what will we say as we look back at this moment about these new technologies about generative AI about these language models and about the hosts of other AI capacities that are even right now under development not just in this country but in China at the countries of our adversaries and all around the world and I think the question that young pose is really the question that faces us will we strike that balance between technological innovation and our ethical and moral responsibility to humanity to Liberty to the freedom of this country and I hope that today's hearing will take us a step closer to that answer thank you Mr chairman thanks thanks Senator Hawley I'm going to turn to the chairman of the Judiciary Committee and the ranking member Senator Graham if they have opening remarks as well yes Mr chairman thank you very much and Senator Hawley as well uh last week in the this committee full committee Senate Judiciary Committee we dealt with an issue that had been waiting for attention for almost two decades and that is what to do with the social media when it comes to the abuse of children we had four bills initially that were considered by this committee and what may be history in the making we passed all four bills with unanimous roll calls unanimous roll calls I can't remember another time when we've done that and an issue that important it's an indication I think of the important position of this Committee in the National debate on issues that affect every single family and affect our future in a profound way 1989 was a historic Watershed year in America because that's when Seinfeld arrived and we have a sitcom which was supposedly about little or nothing which turned out to be enduring I like to watch it obviously and I'm always Marvel when they show the phones that he used in 1989 and I think about those in comparison to what we carry around in our pockets today it's a dramatic change and I guess the question as I look at that is does this change in phone technology that we've witnessed through the sitcom really exemplify a profound change in America still unanswered but the very basic question we face is whether or not this the issue of AI is a quantitative change in technology or qualitative change the suggestions that I've heard from experts in the field suggest it's qualitative is an AI fundamentally different is it a game changer is it so disruptive that we need to treat it differently than other forms of innovation that's the starting point and the second starting point is one that's humbling and that is effect when you look at the record of Congress and dealing with innovation technology and Rapid change were not designed for that in fact the Senate was not created for that purpose but just the opposite slow things down take a harder look at it don't react to public sentiment make sure you're doing the right thing well I've heard of the potential the positive potential of AI and it is enormous you can go through lists of the deployment of technology that would say that an idea you can sketch on a website for a website on a napkin can generate functioning code pharmaceutical companies could use the technology to identify new candidates to treat disease the list goes on and on and then of course the danger and it's profound as well so I'm glad that this hearing has taken place and I think it's important for all of us to participate I'm glad that it's a bipartisan approach we're going to have to scramble to keep up with the pace of innovation in terms of our government public response to it but this is a great start thank you Mr chairman thanks thanks Senator Irvin it is very much a bipartisan approach very deeply and broadly bipartisan and in that Spirit I'm going to turn to my friend Senator Graham thank you that was not written by AI for sure uh let me introduce now the witnesses we're very grateful to you for being here uh Sam Altman is the co-founder and CEO of open AI the AI research and deployment company behind chat GPT and Dally Mr Altman was president of the early stage startup accelerator why combinator from 1914 I'm sorry 2014 to 2019 open AI was founded in 2015. Christina Montgomery is IBM's Vice President Chief privacy and Trust officer overseeing the company's Global privacy program policies compliance and strategy she also chairs IBM's AI ethics board a multi-disciplinary team responsible for the governance of AI and emerging Technologies Christina has served in various roles at IBM including corporate secretary to the company's board of directors she is a global leader in AI ethics and governments and Ms Montgomery also is a member of the United States Chamber of Commerce AI commission and the United States national AI advisory committee which was established in 2022 to advise the president and the national AI initiative office on a range of topics related to AI Gary Marcus is a leading voice in artificial intelligence he's a scientist best-selling author and entrepreneur founder of the robust Ai and geometric AI acquired by Uber if I'm not mistaken an Emeritus professor of Psychology and Neuroscience at NYU Mr Marcus is well known for his challenges to contemporary AI anticipating many of the current limitations decades in advance and for his research in human language development and cognitive Neuroscience thank you for being here and as you may know are custom on the Judiciary is to swear in our Witnesses before they testify so if you would all please rise and raise your right hand you solemnly swear that the testimony that you you are going to give is the truth the whole truth nothing but the truth so how about God thank you Mr Altman we're going to begin with you if that's okay thank you thank you chairman Blumenthal ranking member Holly members of the Judiciary Committee thank you for the opportunity to speak to you today about large neural networks it's it's really an honor to be here even more so in the moment than I expected my name is Sam Altman I'm the Chief Executive Officer of open AI open AI was founded on the belief that artificial intelligence has the potential to improve nearly every aspect of Our Lives but also that it creates serious risks we have to work together to manage we're here because people love this technology we think it can be a printing press moment we have to work together to make it so open AI is an unusual company and we set it up that way because AI is an unusual technology we are governed by a non-profit and our activities are driven by our mission and our Charter which commit us to working to ensure that the broad distribution of the benefits of AI and to maximizing the safety of AI systems we are working to build tools that one day can help us make new discoveries and address some of Humanity's biggest challenges like climate change and curing cancer our current systems aren't yet capable of doing these things but it has been immensely gratifying to watch many people around the world get so much value from what these systems can already do today we love seeing people use our tools to create to learn to be more productive we're very optimistic that they're going to be fantastic jobs in the future and the current jobs can get much better we also love seeing what developers are doing to improve lives for example be my eyes used our new multimodal technology in gpt4 to help visually impaired individuals navigate their environment we believe that the benefits of the tools we have deployed so far vastly outweigh the risks but ensuring their safety is vital to our work and we make significant efforts to ensure that safety is built into our systems at all levels before releasing any new system openai conducts extensive testing engages external experts for detailed reviews and independent audits improves the model's Behavior and implements robust safety and monitoring systems before we release gpt4 our latest model we spent over six months conducting extensive evaluations external red teaming and dangerous capability testing we are proud of the progress that we made gpt4 is more likely to respond helpfully and truthfully and refuse harmful requests than any other widely deployed model of similar capability however we think that regulatory intervention by governments will be critical to mitigate the risks of increasingly powerful models for example the US government might consider a combination of Licensing and testing requirements for development and release of AI models above a threshold of capabilities there are several other areas I mentioned in my written testimony where I believe that companies like ours can partner with governments including ensuring that the most powerful AI models adhere to a set of safety requirements facilitating processes to develop and update safety measures and examining opportunities for Global coordination and as you mentioned uh I think it's important that companies have their own responsibility here no matter what Congress does this is a remarkable time to be working on artificial intelligence but as this technology advances we understand that people are anxious about how it could change the way we live we are too but we believe that we can and must work together to identify and manage the potential downsides so that we can all enjoy the tremendous upsides it is essential that powerful AI is developed with democratic values in mind and this means that U.S leadership is critical I believe that we will be able to mitigate the risks in front of us and really capitalize on this Technology's potential to grow the US economy and the worlds and I look forward to working with you all to meet this moment and I look forward to answering your questions thank you thank you Mr Altman Ms Montgomery chairman Blumenthal ranking member Holly and members of the subcommittee thank you for today's opportunity to present AI is not new but it's certainly having a moment recent breakthroughs in generative Ai and the Technologies dramatic surge in the public attention has rightfully raised serious questions at the heart of today's hearing what are ai's potential impacts on society what do we do about bias what about misinformation misuse or harmful content generated by AI systems Senators these are the right questions and I applaud you for convening today's hearing to address them head on well AI may be having its moment the moment for government to play a role has not passed us by this period of focused public attention onai is precisely the time to Define and build the right guard rails to protect people and their interests at its core AI is just a tool and tools can serve different purposes to that end IBM urges Congress to adopt a Precision regulation approach to AI this means establishing rules to govern the deployment of AI in specific use cases not regulating the technology itself such an approach would involve four things first different rules for different risks the strongest regulation should be applied to use cases with the greatest risks to people and Society second clearly defining risks there must be clear guidance on AI uses or categories of AI supported activity that are inherently high risk this common definition is key to enabling a clear understanding of what regulatory requirements will apply in different use cases and contexts third be transparent so AI shouldn't be hidden consumers should know when they're interacting with an AI system and that they have recourse to engage with a real person should they so desire no person anywhere should be tricked into interacting with an AI system and finally showing the impact for higher risk use cases companies should be required to conduct impact assessments that show how their systems perform against tests for bias and other ways that they could potentially impact the public and to a test that they've done so by following risk-based use case-specific Approach at the core of precision regulation Congress can mitigate the potential risks of AI without hindering innovation but businesses also play a critical role in ensuring the responsible deployment of AI companies active in developing or using AI must have strong internal governance including among other things designating a lead AI ethics official responsible for an organization's trustworthy AI strategy standing up an Ethics board or a similar function as a centralized Clearinghouse for research resources to help guide implementation of that strategy IBM has taken both of these steps and we continue calling on our industry peers to follow suit our AI ethics board plays a critical role in overseeing internal AI governance processes creating reasonable guard rails to ensure we introduce technology into the world and a responsible and safe manner it provides centralized governance and accountability while still being flexible enough to support decentralized initiatives across IBM's Global operations we do this because we recognize that Society grants our license to operate and with AI the stakes are simply too high we must build not undermine the public Trust the era of AI cannot be another era of move fast and break things but we don't have to slam the brakes on Innovation either these systems are within our control today as are the solutions what we need at this pivotal moment is clear reasonable policy and sound guard rails these guardrails should be matched with meaningful steps by the business Community to do their part Congress and the business Community must work together to get this right the American people deserve no less thank you for your time and I look forward to your questions thank you Professor Marcus story thank you Senators today's meeting is historic I'm profoundly grateful to be here I come as a scientist someone who's founded AI companies and is someone who genuinely loves AI but who is increasingly worried there are benefits but we don't yet know whether they will outweigh the risks fundamentally these new systems are going to be destabilizing they can and will create persuasive lies at a scale Humanity has never seen before Outsiders will use them to affect our elections insiders to manipulate our markets and our political systems democracy itself is threatened chatbots will also clandestinely shape our opinions potentially exceeding what social media can do choices about data sets that AI companies use will have enormous unseen influence those who choose the data will make the rules shaping Society in subtle but powerful ways there are other risks too many stemming from the in from the inherent unreliability of current systems a law professor for example was accused by a chatbot of sexual harassment untrue and it pointed to a Washington Post article that didn't even exist the more that that happens the more that anybody can deny anything as one prominent lawyer told me on Friday defendants are starting to claim that plaintiffs are making up legitimate evidence these sorts of allegations undermine the abilities of juries to decide what or who to believe and contribute to the undermining of democracy poor medical advice could have serious consequences too an open source large language model recently seems to have played a role in a person's decision to take their own life the large language model asked the human if you wanted to die why didn't you do it earlier and Then followed up with were you thinking of me when you overdosed without ever referring the patient to the human health that was obviously needed another system rushed out and made available to millions of children told a person posing as a 13 year old how to lie to her parents about a trip with a 31 year old man further threats continue to emerge regularly a month after gpt4 was released openai released chat GPT plugins which quickly LED others to develop something called Auto GPT with direct access to the internet the ability to write source code and increased powers of automation this may well have drastic and difficult to predict security consequences what criminals are going to do here is to create counterfeit people it's hard to even Envision the consequences of that we have built machines that are like Bulls in a china shop powerful Reckless and difficult to control we all more or less agree on the values we would like for our AI systems to honor we want for example for our systems to be transparent to protect our privacy to be free of bias and above all else to be safe but current systems are not in line with these values current systems are not transparent they do not adequately protect our privacy and they continue to perpetuate bias and even their makers don't entirely understand how they work most of all we cannot remotely guarantee that they're safe and hope here is not enough the big tech companies preferred plan boils down to trust us but why should we the sums of money at stake are mind-boggling emissions drift open ai's original mission statement proclaimed our goal is to advance Ai and the way that most is most likely to benefit Humanity as a whole unconstrained by a need to generate Financial return seven years later they're largely beholden to Microsoft embroiled in part in epic battle of search engines that routinely make things up and that's forced alphabet to rush out products and de-emphasize safety Humanity has taken a back seat AI is moving incredibly fast with lots of potential but also lots of risks we obviously need government involved and we need the tech companies involved both big and small but we also need independent scientists not just so that we scientists can have a voice but so that we can participate directly in addressing the problems and evaluating Solutions and not just after products are released but before and I'm glad that Sam mentioned that we need tight collaboration between independent scientists and governments in order to hold the company's feet to the fire allowing independent access to the assist independent Sciences allowing independent scientists access to these systems before they are widely released as part of a clinical trial like safety evaluation is a vital First Step ultimately we may need something like CERN Global International and neutral but focused on AI safety rather than high energy physics we have unprecedented opportunities here but we are also facing a perfect storm of corporate irresponsibility widespread deployment lack of adequate regulation and inherent unreliability AI is among the most world-changing Technologies ever already changing things more rapidly than almost any technology in history we acted too slowly with social media many unfortunate decisions got locked in with lasting Consequence the choices we make now will have lasting effects for decades maybe even centuries the very fact that we are here today in bipartisan fashion to discuss these matters gives me some hope thank you Mr chairman thanks very much Professor Marcus we're going to have seven minute rounds of questioning and I will begin first of all Professor Marcus we are here today because we do face that perfect storm some of us might characterize it more like a bomb in a china shop not a bull and as Senator Hawley indicated there are precedents here not only the Atomic Warfare era but also the Genome Project the research on genetics where there was International cooperation as a result and we want to avoid those past mistakes as I indicated in my opening statement that were committed on social media that is precisely the reason we are here today chat GPT makes mistakes all AI does and it can be a convincing liar what people call hallucinations that might be an innocent problem in the opening of a Judiciary subcommittee hearing where a voice is impersonated mine in this instance I or quotes from research papers that don't exist but chat GPT and Bard are willing to answer questions about life or death matters for example drug interactions and those kinds of mistakes can be deeply damaging I'm interested in how we can have reliable information about the accuracy and trustworthiness of these models and how we can create competition and consumer disclosures that reward greater accuracy the National Institutes of standards and Technology actually already has an AI accuracy test the face recognition vendor test it doesn't solve for all the issues with facial recognition but the scorecard does provide useful information about the capabilities and flaws of these systems so there's work on models to assure accuracy and integrity my question uh let me begin with you Mr Altman is should we consider independent testing labs to provide scorecards and nutrition labels or the equivalent of nutrition labels packaging that indicates to people whether or not the content can be trusted what the ingredients are and what the garbage going in may be because it could result in garbage going out yeah I I think that's a great idea I think that companies should put their own sort of you know hear the results of our test of our model before we release it here's here's where it has weaknesses here's where it has strengths but also independent audits for that are very important these models are getting more accurate over time uh you know this is this is as we have I think said as loudly as anyone this technology is in its early stages it definitely still makes mistakes we find that people that users are pretty sophisticated and understand where the mistakes are that they need or likely to be that they need to be responsible for verifying what the models say that they go off and check it um I I worry that as the models get better and better uh the users can have sort of less and less of their own discriminating thought process around it but but I think users are more capable than we could often give them credit for in in conversations like this I think a lot of disclosures which if you've used chat gbt you'll see about the inaccuracies of the model are also important and I'm I'm excited for a world where companies publish with the models information about how they behave where the inaccuracies are and independent agencies or companies provide that as well I think it's a great idea I alluded in my opening remarks to the the jobs issue the economic effects on employment uh I think you have said uh in fact and I'm going to quote development of superhuman machine intelligence is probably the greatest threat to the continued existence of humanity end quote you may have had in mind the effect on on jobs which is really my biggest nightmare in the long term uh let me ask you uh what your biggest nightmare is and whether you share that concern like with all technological revolutions I expect there to be significant impact on jobs but exactly what that impact looks like is very difficult to predict if we went back to the the other side of a previous technological Revolution talking about the jobs that exist on the other side um you know you can go back and read books of this it's what people said at the time it's difficult I believe that there will be far greater jobs on the other side of this and the jobs of today will get better I think it's important first of all I think it's important to understand and think about gpt4 as a tool not a creature which is easy to get confused and it's a tool that people have a great deal of control over and how they use it and second gpt4 and things other systems like it are good at doing tasks not jobs and so you see already people that are using gpt4 to do their job much more efficiently by helping them with tasks now gbt4 will I think entirely automate away some jobs and it will create new ones that we believe will be much better this happens again my understanding of the history of technology is one long technological Revolution not a bunch of different ones put together but this has been continually happening we as our quality of life raises and as machines and tools that we create can help us live better lives uh the bar raises for what we do and and our human ability and what we spend our time going after uh goes after more ambitious more satisfying projects so there there will be an impact on jobs uh we try to be very clear about that and I think it will require partnership between the industry and government but mostly action by government to figure out how we want to mitigate that um but I'm very optimistic about how great the jobs of the future will be thank you let me ask Ms Montgomery and Professor Marcus for your reactions those questions as well is Montgomery on the jobs Point yeah I mean well it's a hugely important question and it's one that we've been talking about for a really long time at IBM you know we do believe that Ai and we've said it for a long time is going to change every job new jobs will be created many more jobs will be transformed and some jobs will transition away I'm a personal example of a job that didn't exist when I joined IBM and I have a team of AI governance professionals who are in new roles that we created you know as early as three years ago I mean they're new and they're growing so I think the most important thing that we could be doing and can and should be doing now is to prepare the workforce of today and the workforce of tomorrow for partnering with AI Technologies and using them and we've been very involved for for years now in doing that in focusing on skills-based hiring in educating for the skills of the future our skills build platform has seven million Learners and over a thousand courses worldwide focused on skills and we've pledged to train 30 million individuals by 2030 in the skills that are needed for society today thank you Professor Marcus may I go back to the first question as well absolutely on on the subject of nutrition labels I I think we absolutely need to do that I think that there's some technical challenges in that building proper nutrition labels goes hand in hand with transparency the biggest scientific challenge in understanding these models is how they generalize what do they memorize and what new things do they do the more that there's in the data set for example the thing that you want to test accuracy on the less you can get a proper read on that so it's important first of all that scientists be part of that process and second that we have much greater transparency about what actually goes into these systems if we don't know what's in them then we don't know exactly how well they're doing when we give something new and we don't know how good a benchmark that will be for something that's entirely novel so I could go into that more but I want to flag that second is on jobs past performance history is not a guarantee of the future it has always been the case in the past that we have had more jobs than new jobs new professions come in as new technologies come in I think this one's going to be different and the real question is over what time time scale is it going to be 10 years is it going to be 100 years and I don't think anybody knows the answer to that question I think in the long run so-called artificial general intelligence really will replace a large fraction of human jobs we're not that close to artificial general intelligence despite all of the media hype and so forth I would say that what we have right now is just a small sampling of the AI that we will build in 20 years people will laugh at this as I think it was Senator Hawley made the but maybe Senator Durbin made the example about this it was Senator Durbin made the example about cell phones when we look back at the AI of today 20 years ago we'll be like wow that stuff was really unreliable it couldn't really do planning which is an important technical aspect it's reasoning wasability and reasoning abilities were limited but when we get to AGI or artificial general intelligence mainly let's say it's 50 years that really is going to have I think profound effects on labor and there's just no way around that and last I don't know if I'm allowed to do this but I will note that Sam's worst fear I do not think is employment and he never told us what his worst fear actually is and I think it's germane to find out thank you I'm going to ask Mr Altman if he cares to respond look we have tried to be very clear about the magnitude of the risks here I I think jobs and employment and what we're all going to do with our time really matters I agree that when we get to very powerful systems the landscape will change I think I'm just more optimistic that we are incredibly creative and we find new things to do with better tools and that will keep happening um my worst fears are that we cause significant we the field the technology the industry caused significant harm to the world I think that could happen a lot of different ways it's why we started the company it's a big part of why I'm here today and why we've been here in the past and we've been able to spend some time with you I think if this technology goes wrong it can go quite wrong and we want to be vocal about that we want to work with the government to prevent that from happening but we we try to be very clear-eyed about what the downside case is and the work that we have to do to mitigate that thank you and and our hope is that the rest of the industry will follow the example that you and IBM Ms Montgomery have set by coming today and meeting with us as you have done privately in helping to guide what we're going to do so that we can Target the harms and avoid unintended consequences to the good thanks Senator Hawley thank you again Mr chairman thanks to the witnesses for being here Mr Altman I think you grew up in St Louis I did not mistaken it's great to see it is a great place Missouri in here it is thank you I wanna I want that noted especially underlined in the record Missouri is a great place that is the takeaway from today's hearing maybe we'll just stop there Mr chairman um let me ask you Mr Altman I think I'll start with you and I'll just preface by saying my questions here are an attempt to get my head around and to ask all of you to help us to get our heads around what these this generative AI particularly the large language models what it can do is I'm trying to understand its capacities and then its significance so I'm looking at a paper here entitled large language models trained on media diets can predict public opinion this is just posted about a month ago the authors are too Andreas and Roy and their conclusion of this work was done at MIT and then also at Google the conclusion is that large language models can indeed predict public opinion and they go through and and model why this is the case and they they conclude ultimately that an AI system can predict human survey responses by adapting a pre-trained language model to subpopulation specific media diets in other words you can feed the model a particular set of media inputs and it can with remarkable accuracy and the paper goes into this predict then what people's opinions will be I I'm I want to think about this in the context of Elections if these large language models can even now based on the information we put into them quite accurately predict public opinion you know ahead of time I mean predict it's before you even ask the public these questions what will happen when entities whether it's corporate entities or whether it's governmental entities or whether it's campaigns or whether it's foreign actors take this survey information these predictions about public opinion and then fine-tune strategies to elicit certain responses certain behavioral responses I mean we already know this committee is her testimony I think three years ago now about the effect of something as prosaic it now seems as Google search the effect that this has on voters in an election particularly undecided voters in the final days of an election who may try to get information from Google search and what an enormous effect the ranking of the Google search the articles that it returns has come an enormous effect on an undecided voter this of course is orders of magnitude far more powerful far more significant a far more directive if you like so Mr Altman maybe you can help me understand here what some of the significance of this is should we be concerned about models that can large language models that can predict survey opinion and then can help organizations entities fine-tune strategies to illicit behaviors from voters should we be worried about this for our elections yeah uh thank you Senator Hawley for the question it's one of my areas of greatest concern the the the more General ability of these models to manipulate to persuade and to provide sort of one-on-one uh you know interactive disinformation I think that's like a broader version of what you're talking about but given that we're going to face an election next year and these models are getting better I think this is a significant area of concern I think there's a lot there's a lot of policies that companies can voluntarily adopt and I'm happy to talk about what we do there I do think some regulation would be quite wise on this topic uh someone mentioned earlier it's something we really agree with people need to know if they're talking to an AI if content that they're looking at might be generated or might not I think it's a great thing to do is to make that clear I think we also will need rules guidelines about what what's expected in terms of disclosure from a company providing a model that could have these sorts of abilities that you talk about so I'm nervous about it I think people are able to adapt quite quickly when Photoshop came onto the scene a long time ago you know for a while people were really quite fooled by photoshopped images and then pretty quickly developed an understanding that images might be photoshopped this will be like that but on steroids and the the interactivity the ability to really model predict humans well as you talked about I think is going to require a combination of companies doing the right thing regulation and public education do you Mr Professor Marcus do you want to address this yeah I'd like to add two things one is in the appendix to my remarks I have two papers to make you even more concerned um one is in the Wall Street Journal just a couple days ago called help my political beliefs were altered by a chat bot and I think the scenario you raised was that we might basically observe people and use surveys to figure out what they're saying but as Sam just acknowledged the risk is actually worse that the systems will directly maybe not even intentionally manipulate people and that was the thrust of the Wall Street Journal article and it links to an article that I've also linked to called interacting and it's not yet published not yet peer-reviewed interacting with opinionated language models changes users views and this comes back ultimately to data one of the things that I'm most concerned about with gpt4 is that we don't know what it's trained on I guess Sam knows but the rest of us do not and what it is trained on has consequence Sciences for essentially the biases of the system we could talk about that in technical terms but how these systems might lead people about depends very heavily on what data is trained on them and so we need transparency about that and we probably need scientists in there doing analysis in order to understand what the political influences of for example of these systems might be and it's not just about politics it can be about health it could be about anything these systems absorb a lot of data and then what they say reflects that data and they're going to do it differently depending on what what's in that data so it makes a difference if they're trained on the Wall Street Journal as opposed to the New York Times or or Reddit I mean actually they're largely trained on all of this stuff but we don't really understand the composition of that and so we have this issue of potential manipulation and it's even more complex than that because it's subtle manipulation people may not be aware of what's going on that was the point of both the Wall Street Journal article and the other article that I called your attention to let me ask you about AI systems trained on personal data the kind of data that for instance the social media companies the major platforms Google meta Etc collect on all of us routinely we've had many a chat about this in this committee over many a year now but the massive amounts of data personal data that the companies have on each one of us an AI system that is that is trained on that individual data that knows each of us better than ourselves and also knows the billions of data points about human behavior human language interaction generally wouldn't we be able wouldn't we can't we foresee an AI system that is extraordinarily good at determining what will grab human attention and what will keep an individual's attention and so for the war for attention the war for uh clicks that is currently going on on all of these platforms is how they make their money I'm just imagining a an AI system these these AI models supercharging that war for attention such that we now have technology that will allow individual targeting of a kind we have never even imagined before where the AI will know exactly what Sam Altman finds uh attention grabbing will know exactly what Josh Hawley finds attention grabbing will be able to elicit to grab our attention and then elicit responses from us in a way that we have here before not even been able to imagine should we be concerned about that for its corporate applications for the monetary applications for the manipulation that that could come from that Mr almond uh yes we should be concerned about that to be clear openai does not we're not off you know we wouldn't have an ad-based business model so we're not trying to build up these profiles of our users we're not we're not trying to get them to use it more actually we'd love it if they use it less because we don't have enough gpus um but I think other companies are already and certainly will in the future use AI models to create you know very good ad predictions of what a user will like I think it's already happening in many ways Miss Marcus anything you want to add hyper yes um and perhaps Ms Montgomery will want to to as well I don't but um hyper targeting of advertising is definitely going to come I agree that that's not been open ai's business model um of course now they're working for Microsoft and I don't know what's in Microsoft's thoughts um but we will definitely see it maybe it will be with open source language models I don't know but the technology there is let's say part way there to being able to do that and we'll certainly get there so we're an Enterprise technology company not consumer focused so the space isn't one that we necessarily operate in in terms of but these issues are hugely important issues and it's why we've been out ahead in developing the technology that will help to ensure that you can do things like produce a fact sheet that has the ingredients of what your data is trained on data sheets model cards all those types of things and calling for as I've mentioned today transparency so you know what the algorithm was trained on and then you also know and can manage and monitor continuously over the life cycle of an AI model the behavior and the performance of that model Senator Durbin thank you I think what's happening today in this hearing room is historic I can't recall when we've had people representing large corporations or private sector entities come before us and plead with us to regulate them in fact many people in the Senate have base their careers on the opposite that the economy will Thrive if Government gets the hell out of the way and what I'm hearing instead today is that stop me before I innovate again message and I'm just curious as to how we're going to achieve this as I mentioned section 230 in my opening remarks we learned something there we decided that on Section 230 that we were basically going to absolve the industry from liability for a period of time as it came into being well Mr Oldman on the podcast earlier this year you agreed with host Kara Swisher that section 230 doesn't apply to generative AI and that developers like open AI should not be entitled to full immunity for harms caused by their products so what have we learned from 230 that applies to your situation with AI thank you for the question Senator I I don't know yet exactly what the right answer here is I'd love to collaborate with you to figure it out I do think for a very new technology we need a new framework certainly companies like ours bear a lot of responsibility for the tools that we put out in the world but tool users do as well and how we want and also people that will build on top of it between them and the the end consumer um and how we want to come up with a live a liability framework there is a super important question um and we'd love to work together the point I want to make is this when it came to online platforms the inclination of the government was get out of the way this is a new industry don't over regulate it in fact give them some breathing space and see what happens I'm not sure I'm happy with the outcome as I look at online platforms me either and the harms that they have created problems that we've seen demonstrated in this committee child exploitation cyber bullying online drug sales and more I don't want to repeat that mistake again and what I hear is the opposite suggestion from the private sector and that is come in the front end of this thing and establish some liability standards Precision regulation for a major company like IBM to come before this committee and say to the government please regulate us can you explain the difference in thinking from the past and now yeah absolutely um so for us this comes back to the issue of trust and Trust in the technology trust is our license to operate as I mentioned in my remarks and so we firmly believe and we've been calling for precision regulation of artificial intelligence for years now this is not a new position we think that technology needs to be deployed in a risk responsible and clear way that people we've taken principles around that trust and transparency we call them are principles that were articulated years ago and build them into practices that's why we're here advocating for precision regulatory approach so we think that AI should be regulated at the point of risk essentially and that's the point at which technology meets Society let's take a look at what that might appear to be members of Congress are pretty smart a lot of people maybe not as smart as we think we are many times and government certainly has a capacity to do amazing things but when you talk about our ability to respond to the current Challenge and perceive challenge of the future challenges which you all have described in terms which are hard to forget as you said Mr Altman things can go quite wrong she said Mr Marcus democracy is threatened I mean the magnitude of the challenge you're giving us is substantial I'm not sure that we respond quickly and with enough expertise to deal with it Professor Marcus you made a reference to CERN the international Arbiter of nuclear research I suppose I don't know if that's a fair characterization but it's a characterization I'll start with what is it what agency of this government do you think exists that could respond to the challenge that you've laid down today we have many agencies that can respond in some ways for example the FTC um we have CC and there are many agencies that can but my view is that we probably need a cabinet level uh organization within the United States in order to address this and my reasoning for that is that the number of risks is large the amount of information to keep up on is so much I think we need a lot of technical expertise I think we need a lot of coordination of these efforts so there is one model here where we stick to only existing law and try to shape all of what we need to do and each agency does their own thing but I think that AI is going to be such a large part of our future and is so complicated and moving so fast this does not fully solve your problem about a dynamic world but it's a step in that direction to have an agency that's full-time job is to do this I personally have suggested in fact that we should want to do this at a global way I wrote an article on The Economist I have a link in here an invited essay for the economist suggesting we might want an international Agency for AI That's what I wanted to go to next and that is the fact that I'll get it aside from the CERN and nuclear examples because government was involved in that from day one at least in the United States but now we're dealing with Innovation which doesn't necessarily have a boundary we may create a great U.S agency and I hope that we do that may have jurisdiction over U.S corporations and U.S activity but doesn't have a thing to do with what's going to bombard us from outside the United States how do you give this International Authority the authority to regulate in a fair way for all entities involved in AI I think that's probably over my pay grade I would like to see it happen and I think it may be inevitable that we push there I mean I think the politics behind it are obviously complicated I'm really heartened by the degree to which this room is bipartisan and supporting the same things and that makes me feel like it might be possible I would like to see the United States take leadership in such organization it has to involve the whole world and not just the US to work properly I think even from the perspective of the companies it would be a good thing so the companies themselves do not want a situation where you take these models which are expensive to train and you have to have 190 some of them you know one for every country that that wouldn't be a good way of operating when you think about the energy costs alone just for training these systems it would not be a good model if every country has its own policies and each for each jurisdiction every company has to train another model and maybe you know different states are different so Missouri and California have different rules and so then that requires even more training of these expensive models with huge climate impact um and I mean just it would be very difficult for the companies to operate if there was no Global coordination and so I think that we might get the companies on board if there's bipartisan support here and I think there's support around the world that is entirely possible that we could develop such a thing but obviously there are many you know nuances here of diplomacy that are over my pay grade I I would love to learn from you all to try to help make that happen Mr Altman can I weigh in just briefly briefly please uh I want to Echo support for what Mr Marcus said I think the U.S should lead here and do things first but to be effective we do need something Global as you mentioned this can this can happen everywhere there is precedent I know it sounds naive to call for something like this and it sounds really hard there is precedent we've done it before with the iaea we've talked about doing it for other Technologies they're given what it takes to make these models the chip supply chain the sort of limited number of competitive gpus the power the US has over these companies I think there are paths to the U.S setting some International standards that other countries would need to collaborate with and be part of that are actually workable even though it sounds on its face like a impractical idea and I think it would be great for the world thank you Mr chairman thanks Senator Durbin and in fact I think we're going to hear more about what Europe is doing European Parliament already is acting on an AI act uh on social media Europe is ahead of us uh we need to be in the lead I think your your point is very well taken let me turn to Senator Graham Senator Blackburn thank you Mr chairman and thank you all for being here with us today I put into my chat GPT account should Congress regulate AI chat GPT and it gave me four Pros four cons and says ultimately the decision rests with Congress and deserves careful consideration so on that you know it was uh very balanced I recently visited with the Nashville Technology Council I represent Tennessee and of course you had people there from Health Care Financial Services Logistics educational entities and they're concerned about what they see happening with AI with the utilizations for their companies Miss Montgomery you know some similar to you they've got Health Care people are looking at disease analytics they're looking at predictive diagnosis how this can better the outcomes for patients la Logistics industry looking at ways to save time and money and yield efficiencies you've got financial services that are saying how does this work with Quantum how does it work with blockchain how can we use this but uh it I think as we have talked with them Mr chairman one of the things that continues to come up is yes Professor Marcus as you were saying the EU different entities are ahead of us in this but we have never established a federally preem given preemption for online privacy for data security and put some of those foundational elements in place which is something that we need to do as we look at this and it will require that Commerce Committee Judiciary Committee decide how we move forward so that people own their virtual you and um Mr Altman I was glad to see last week that your open AI models are not going to be trained using consumer data I think that that is important and if we have a second round I've got a host of questions for you on data security and privacy but I think it's important to let people control their virtual you their information in these settings and I want to come to you on music and content creation because we've got a lot of songwriters and artists and a I think we have the best creative community on the face of the Earth they're in Tennessee and they should be able to decide if they're copyrighted songs and images are going to be used to train these models and I'm concerned about open ai's jukebox it offers some re-renditions in the style of Garth Brooks which suggests that open AI is trained on Garth Brooks songs I went in this weekend and I said write me a song that sounds like Garth Brooks and it gave me a different version of Simple Man so it's interesting that it would do that but you're training it on these copyrighted songs these MIDI files these sound Technologies so as you do this who owns the rights to that AI generated material and using your technology could I remake a song insert content from my favorite artist and then on the creative rights to that song thank you Senator uh this is an area of great interest to us I would say first of all we think that creators deserve control over how their Creations are used and what happens sort of beyond the point of them releasing it into the world um second I think that we need to figure out new ways with this new technology that creators can win succeed have a vibrant life and I'm optimistic that this will present it then let me ask you this how do you compensate the art the artist that's exactly what I was going to say okay um we'd like to we're working with artists now visual artists musicians uh to figure out what people want there's a lot of different opinions unfortunately at some point we'll have let me ask you this do you favor something like Sound Exchange that has worked in the area radio I'm not familiar with exchange I'm sorry okay you've got your team behind you get back to me on that that would be a third party entity okay so let's discuss that let me move on um can you commit as you've done with consumer data not to train chat GPT open AI jukebox or other AI models on artists and songwriters copyrighted works or use their voices and their likenesses without first receiving their consent so first of all jukebox is not a product we offer that was a research release but it's not you know unlike chat GPT or dollar but we've lived through Napster yes but that was something that really cost a lot of artists a lot of money oh I understand yeah for sure digital distribution era I don't I don't know the numbers on jukebox on the top of my head as a research release I can I can follow up with your office but it's not jukebox is not something that gets much attention or usage it was put out to to show that something's possible well Senator Durbin just said you know and I think it's a fair warning to you all if we're not involved in this from the get-go and you all already are a long way down the path on this but if we don't step in then this gets away from you so are you working with a copyright office are you considering protections for Content generators and creators in generative AI yes we are absolutely engaged on that again to reiterate my earlier point we think that content creators content owners need to benefit from this technology exactly what the economic model is we're still talking to artists and content owners about what they want I think there's a lot of ways this can happen but very very clearly no matter what the law is the right thing to do is to make sure people get significant upside benefit from this new technology and we believe that it's really going to deliver that but that content owners likenesses people totally deserve control over how that's used and to benefit from it okay so on privacy then how do you plan to account for the collection of voice and other user-specific data things that are copyrighted user-specific data through your AI applications because if I can go in and say write me a song that sounds like Garth Brooks and it takes part of an existing song there has to be a compensation to that artist for that utilization and that use if it was radio play it would be there if it was streaming it would be there so if you're going to do that what is your policy for making certain you're accounting for that and you're protecting that individual's right to privacy and their right to secure that data and that created work so a few thoughts about this uh number one we think that people should be able to say I don't want my personal data trained on that's I think that's right that gets to a national Privacy Law which many of us here on the Deus are working toward getting something that we can use yeah I think a strong privacy my time's expired look in the old back thank you Mr chip thanks Senator Blackburn Senator corporate thank you very much Mr chairman um and uh Senator Blackburn I love Nashville I love Tennessee love your music but I will say I use chat GPT and just asked what are the top creative song artists of all time and two of the top three were from Minnesota that would be uh Prince I'm sure they moved Prince and Bob Dylan okay all right so let us let us continue one thing AI won't change and you're seeing it here all right so on a more serious note though my staff and I um in my role as chair of the rules committee and leading a lot of the election bill and we just introduced a bill that's representative Yvette Clark from New York introduced over the house Senator Booker and Bennett and I did on political advertisements but that is just of course the tip of the iceberg you know this from your discussions with Senator Hawley and others about the images and my own view it was Senator grams of section 230 is that we just can't let people make stuff up and then not have any consequence but I'm going to focus in on what my job one of my jobs will be on the rules committee and that is election misinformation and we just asked Chef GPT to do a tweet about a polling location in Bloomington Minnesota and said there are long lines at this polling location at atonement Lutheran Church of where should we go now albeit it's not an election right now but the answer the tweet that was drafted was a completely fake thing go to one two three four Elm Street and so you can imagine what I'm concerned about here with an election upon us with primary elections upon us that we're going to have all kinds of misinformation and I just want to know what you're planning on doing it doing about it I know we're going to have to do something soon not just for the images of the candidates but also for misinformation about the actual polling place is and election rules thank you Senator that we we talked about this a little bit earlier we are quite concerned about the impact this can have on elections I think this is an area where hopefully the entire industry and the government can work together quickly there's there's many approaches and I'll talk about some of the things we do but before that I think it's tempting to use the frame of social media um but this is not social media this is different and so the the response that we need is different you know this is a tool that a user is using to help generate content more efficiently than before they can change it they can test the accuracy of it if they don't like it they can get another version um but it still then spreads through social media or other ways like chat gbt is a you know single player experience where you're just using this um and so I think as we think about what to do that's that's important to understand there's a lot that we can and do do there um there's things that the model refuses to generate we have policies uh we also importantly have monitoring so at scale uh we can detect someone generating a lot of those tweets even if generating one tweet is okay yeah and of course there's going to be other platforms and if they're all spouting out fake election information I just I I think what happened in the past with Russian interference and like it's just going to be a tip of the iceberg with some of those fake ads so that's number one number two is the impact on intellectual property and Senator Blackburn was getting at some of this with song rights um and I have serious concerns about that but news content um so Senator Kennedy and I have a bill that was really quite straightforward that would simply allowed the um the new news organizations an exemption to be able to negotiate with basically Google and Facebook Microsoft was supportive of the bill but basically negotiate with them to get better rates and be able to not have some leverage and other countries are doing this Australia and the like and so my question is when we already have a study by Northwestern predicting that one-third of the U.S newspapers are that roughly existed two decades are going to go are going to be gone by 2025 unless you start compensating for everything from book movies books yes but also news content we're going to lose any realistic content producers and so I'd like your response to that and of course there is an exemption for copyright in section 230 but I think asking little newspapers to go out and Sue all the time just can't be the answer they're not going to be able to keep up yeah like it is my hope that tools like what we're creating can help news organizations do better I think having a vibrant having a vibrant National media is critically important and let's call it round one of the internet has not been great for that right we're talking here about local that you know report on your high school football scores and a scandal in your city council those kinds of things for sure they're the ones that are actually getting the worst the little radio stations and broadcast but do you understand that this could be exponentially worse in terms of local news content if they're not compensated well because what they need is to be compensated for their content and not have it stolen yeah again our our model you know our the current version of uh gpt4 ended training in 2021 it's not it's not it's not a good way to find recent news uh and it's I don't think it's a service that can do a great job of linking out although maybe with our plugins it's it's possible uh if there are things that we can do to help local news we would certainly like to again I think it's it's critically important okay um May I add something there yeah but let me just ask you a question you can combine them quick more transparency on the platforms um Senator Coons and Senator Cassidy and I have the platform accountability transparency act to give researchers access to this information of the algorithms and the like on social media data would that be helpful and then why don't you just say yes or no and then go at his uh the transparency is absolutely critical here to understand the political ramifications the bias ramifications and so forth we need transparency about the data we need to know more about how the models work we need to have scientists have access to them I was just going to amplify your earlier point about local news a lot of news is going to be generated by these systems they're not reliable News Guard already is a study I'm sorry it's not in my appendix but I will get it to your office showing that something like 50 websites are already generated by Bots we're going to see much much more of that and it's going to make it even more competitive for the local news organizations and so the quality of the sort of overall news Market is going to decline as we have more generated content by systems that aren't actually reliable in the content they're generated thank you and thank you at a very timely basis to make the argument why we have to mark up this bill again in June I appreciate it thank you Senator Graham thank you Mr chairman and Senator Hawley for having this I'm trying to find out how it is different than social media and learn from the mistakes we made with social media the idea of not suing social media companies is to allow the internet to flourish because if I slander you uh you can sue me if you're a billboard company and you put up the slander can you sue the billboard company we said no basically section 230 is being used by social media companies to high to avoid liability uh for activity that other people generate when they refuse to comply with their terms of use a mother calls up the company and says this app is being used to bully my child to death you promise in the terms of use you would prevent bullying and she calls three times she gets no response the child kills herself and they can't sue do you all agree we don't want to do that again yes if I may speak for one second there's a fundamental distinction between reproducing content and generating content yeah but you you would like liability where people are harmed absolutely yes in fact IBM has been publicly advocating to condition liability on a reasonable Care standard so let me just make sure I understand the law as it exists today Mr Solomon thank you for coming your company is not claiming that section 230 applies to the tool you have created yeah we're claiming we need to work together to find a totally new approach I don't think section 230 is the even the right framework okay so under the law it exists today this tool you create if I'm harmed by it can I sue you that is beyond my area of legalization not for that no have you ever been sued at all uh the your company yeah open AI gets sued uh yeah we've gotten sued before okay and what for um I mean they've mostly been like pretty frivolous things like I think happens to any company but like the examples my colleagues have given from artificial intelligence that could literally ruin our lives can we go to the company that created that tool in suom is that your understanding yeah I think there needs to be clear responsibility by the companies but you're not claiming any kind of legal protection like section 2 230 applies to your industry is that correct no I don't think we're I don't I don't think we're saying anything Mr Marcus um when it comes to Consumers there seems to be like three time tested ways to protect consumers against any product um statutory schemes which are non-existent here um legal systems which may be appear here but not social media and agencies go back to Senator Hawley the atom bomb has put a cloud over Humanity but nuclear power could be one of the solutions to climate change so what I'm trying to do is make sure that you just can't go build a nuclear power plant hey Bob what would you like to do today let's go build a nuclear power plant you have a nuclear Regulatory Commission that governs how you build a plant and it's licensed do you agree Mr Alderman that these tools you're creating should be licensed yeah we've been calling for this we think any that's the simplest way you get a license and do you agree with me the the simplest way and the most effective way is have an agency that is more Nimble and smarter than Congress which should be easy to create overlooking what you do yes we'd be enthusiastic about that you agree with that Mr Marcus absolutely you'd agree with that that's Montgomery I would have some nuances I think we need to build on what we have in place already today we don't have an agency Regulators wait a minute nope nope nope we don't have an agency that regulates the technology so should we have one but a lot of the issues I I don't think so a lot of these wait a minute wait a minute so IBM says we don't need an agency uh interesting should we have a license required for these tools so so what we believe is that we need to write a simple question should you get a license to produce one of these tools I think it comes back to some of them potentially yes so what I said at the onset is that we need to um clearly Define risks do you claim section 230 applies in this area at all we are not a platform company and we've again long advocated for a reasonable Care standard and section I just don't understand how you could say that you don't need an agency to deal with the most transformative technology maybe ever well it's a transformative technology that can disrupt Life as we know it good and bad I think it's a transformative technology certainly and the conversations that we're having here today have been really bringing to light the fact that this is the domains and the issues this one with you has been very enlightening to me Mr Allman why are you so willing to have an agency Senator we've been clear about what we think the upsides are and I think you can see from users how much they enjoyed how much value they're getting out of it but we've also been clear about what the downsides are and so that's why we think we need an agency system it's a major tool to be used by a lot it's a major new technology yeah if you make a ladder and the ladder doesn't work you can see the people made the letter but there are some standards out there to make a letter so that's why we're agreeing with you yeah that's right I think you're on the right track so here's what my two cents worth for the committee is that we need to empower an agency that issues in a license and can take it away wouldn't that be some incentive to do it right if you could actually be taken out of business clearly that should be part of what an agency can do now and you also agree that China is doing AI research is that right correct this world organization that doesn't exist maybe it will but if you don't do something about the China part of it you'll never quite get this right do you agree well that that's why I think it doesn't necessarily have to be a world organization but there has to be some sort of and there's a lot of options here there has to be some sort of standard some sort of set of controls that do have Global Effect yeah because you know other people doing this I got 15 military application how can AI change the Warfare and you got one minute I got one minute yeah all right this is that's a tough question for one minute um this is very far out of my area of expertise uh but I give you one example a drone can a drone you program you can plug into a drone the coordinates and it can fly out it goes over this Target and it drops a missile on this car moving down the road and somebody's watching it could AI create a situation where a drone can select the target itself I think we shouldn't allow that well can it be done sure thanks underground Senator thank you Senator Blumenthal Senator Hawley for convening this hearing for working closely together to come up with this compelling panel of witnesses and beginning a series of hearings on this transformational technology but we recognize the immense promise and substantial risks associated with generative AI Technologies we know these models can make us more efficient help us learn new skills open whole new vistas of creativity but we also know that generative AI can authoritatively deliver wildly incorrect information it can hallucinate as is often described it can impersonate loved ones it can encourage self-destructive behaviors and it can shape public opinion and the outcome of Elections Congress thus far has demonstrably failed to responsibly enact meaningful regulation of social media companies with serious harms that have resulted that we don't fully understand Senator Globus referenced in her questioning a bipartisan bill that would open up social media platforms underlying algorithms we have struggled to even do that to understand the underlying technology and then to move towards responsible regulation we cannot afford to be as late to responsibly regulating generative AI as we have been to social media because the consequences both positive and negative will exceed those of social media by orders of magnitude so let me ask a few questions designed to get at both how we assess the risk what's the role of international regulation and how does this impact AI Mr Altman I appreciate your testimony about the ways in which open AI assesses the safety of your models through a process of iterative deployment the fundamental question embedded in that process though is how you decide whether or not a model is safe enough to deploy and safe enough to have been built and then let go into the the wild I understand one way to prevent generative AI models from providing harmful content is to have humans identify that content and then train the algorithm to avoid it there's another approach that's called constitutional AI that gives the model a set of values or principles to guide its decision making would it be more effective to give models these kinds of rules instead of trying to require or compel training the model on all the different potentials for harmful content thank you Senator it's it's a great question uh I like to frame it by talking about why we deploy at all like why we put these systems out into the world there's the obvious answer about there's benefits and people are using it for all sorts of wonderful things and getting great value and that makes us happy but a big part of why we do it is that we believe that iterative deployment and giving people in our institutions and you all time to come to grips with this technology to understand it to find its limitations it benefits that the regulations we need around it what it takes to make it safe that's really important going off to build a super powerful AI system in secret and then dropping it on the world all at once I think would not go well so a big part of our strategy is while these systems are still relatively weak and deeply imperfect to find ways to get people to have experience with them to have contact with reality and to figure out what we need to do to make it safer and better and that is the only way that I've seen in the history of new technology and products of this magnitude to get to a very good outcome and so that that interaction with the world is very important now of course before we put something out uh it needs to meet a bar of safety and uh and again we spent well over six months with gpt4 after we finished training it going through all of these different things and deciding also what the standards were going to be before we put something out there trying to find the harms that we knew about uh put it and and how to address those one of the things that's been gratifying to us is even some of our biggest critics have looked at gpt4 and said wow open AI made huge progress on I could focus briefly on whether or not a constitutional model that gives values would be worth it I was just about to get there all right sorry about that um yeah I think giving the models values up front uh is an extremely important Set uh you know rlhf is another way of doing that same thing but somehow or other you are with synthetic data or human generated data you're saying here are the values here's what I want you to reflect or here are the wide bounds of everything that Society will allow and then within there you pick as the user you know if you want value system over here or value system over there um we think that's very important there's multiple technical approaches but we need to give policy makers and the world as a whole the tools to say here's the values and Implement them thank you Ms Montgomery you serve on an AI ethics Board of a long established company that has a lot of experience with AI I'm really concerned that generative AI Technologies can undermine the faith of democratic values and the institutions that we have the Chinese are insisting that AI as being developed in China reinforce the core values of the Chinese Communist Party in the Chinese system and I'm concerned about how we promote AI that reinforces and strengthens open markets open societies and democracy in your testimony you're advocating for AI regulation tailored to the specific way the technology is being used not the underlying technology itself and the EU it's moving ahead with an AI act which categorizes AI products based on level of risk you all in different ways have said that you view elections and the shaping of election outcomes and disinformation that can influence elections as one of the highest risk cases one that's entirely predictable we have attempted so far unsuccessfully to regulate social media after the demonstrably harmful impacts of social media on our last several elections what advice do you have for us about what kind of approach we should follow and whether or not the EU direction is the right one to pursue I mean the conception of the EU AI Act is very consistent with this concept of precision regulation where you're regulating the use of the technology in context so absolutely that approach makes a ton of sense it's what um I advocated for at the onset different rules for different risks so in the case of Elections absolutely any algorithm being used in that context should be required to have disclosure around the data being used the performance of the model anything along those lines is really important guard rails need to be in place and and on the point just come back to the question of of whether we need an independent agency I mean I think we don't want to slow down regulation to address real risks right now right so we have existing regulatory authorities in place who have been clear that they have the ability to regulate in their respective domains a lot of the issues we're talking about today span multiple domains elections and the like so if I could I'll just assert that those existing regulatory bodies and authorities are under-resourced and lack many of the statutory regulatory powers that they need correct we have failed to deliver our data privacy even though industry has asking us to regulate data privacy if I might Mr Marcus I'm I'm interested also what international bodies are best positioned to convene multilateral discussions to promote responsible standards we've talked about a model being CERN and nuclear energy I'm concerned about proliferation and non-proliferation we've also talked I would suggest that the ipcc a U.N body helped at least provide a scientific Baseline of what's happening in climate change so that even though we may disagree about strategies globally we've come to a common understanding of what's happening and what should be the direction of intervention I'd be interested Mr Marcus if you could just give us um your thoughts on who's the right body internationally to convene a conversation and one that could also reflect our values I'm still feeling my way on that issue I think global politics is not my specialty I'm an AI researcher but I I have moved towards policy in in recent months really because of my great concern about all of these risks I think certainly the UN UNESCO and has its guidelines should be involved and at the table and maybe things work under them and maybe they don't but they should have a strong voice and and help to develop this the oacd has also been thinking greatly about this number of organizations have internationally I I don't feel like I personally am qualified to say exactly what the right model is there well thank you I think we need to pursue this both at the national level and the international level I'm the chair of the IP subcommittee of the Judiciary Committee in June and July we will be having hearings on the impact of AI on patents and copyrights you can already tell from the questions of others there will be a lot of interest I look forward to following up with you about that topic I know Mr chairman I look forward to helping as much as possible thank you very much Bank Senator Coons Senator Kennedy thank you all for being here permit me to share with you three hypotheses that I would like you to assume for the moment to be true hypothesis number one many members of Congress do not understand artificial intelligence hypothesis number two that absence of understanding may not prevent Congress from plunging in with enthusiasm and trying to regulate this technology in a way that could hurt this technology hypothesis number three that I would like you to assume there is likely a berserk wing of the artificial intelligence community that intentionally or unintentionally could use artificial intelligence to kill all of us and hurt us the entire time that we are dying assume all of those to be true please tell me in plain English two or three reforms regulations if any that you would you would Implement if you were queen or King for a Day Ms Montgomery I think it comes back again to transparency and explainability in AI we absolutely need to know and have companies attest what do you mean by transparency so disclosure of the data that's used to train AI disclosure of the model and how it performs and making sure that there's continuous governance over these models that we are the Leading Edge into governance Foundation technology governance organizational governance rules and clarification that are needed that this which Congress I mean this is your chance folks to tell us how to get this right please use it right I mean I think again the rules should be focused on the use of AI in certain contexts so if you look at for example so if you look at the EU AIS it has certain uses of AI that it says are just simply too dangerous and will be outlawed in these okay so we ought to first pass the law that says you can use AI for these uses but not others is that is that what you're saying we need to define the highest risk usage is there anything else um and then of course requiring things like impact assessments and transparency requiring companies to show their work protecting data that's used to train AI in the first place as well Professor Marcus if you could be specific this was your shot man talking plain English and tell me what if any rules we ought to implement and police don't just use Concepts I'm looking for specificity number one a safety review like we use with the FDA prior to widespread deployment if you can introduce something to 100 million people somebody has to have their eyeballs on it there you go okay that's a good one number sure I agree with it but that's a good one what else you didn't ask for three that you would agree with number two a Nimble monitoring agency to follow what's going on not just pre-review but also post as things are out there in the world with authority to call things back which we've discussed today and number three would be funding geared towards things like AI Constitution AI that can reason about what it's doing I would not leave things entirely to current technology which I think is poor at behaving in ethical fashion and behaving in honest fashion and so I would have funding to try to basically focus on AI Safety Research that term has a lot of complications in my field there's both safety let's say short term and long term and I think we need to look at both rather than just funding models to be bigger which is the popular thing to do we need to find projects to be more trustworthy because I want to hear from Mr Alton Mr Altman here's your shot thank you Senator uh number one I would form a new agency that licenses any effort above a certain scale of capabilities and can take that license away and ensure compliance with safety standards number two I would create a set of safety standards focused on what you said in your third hypothesis as the dangerous capability evaluations one example that we've used in the past is looking to see if a model can self-replicate and self-exfiltrate into the wild we can give your office a long other list of the things that we think are important there but specific tests that a model has to pass before it can be deployed into the world and then third I would require independent audits so not just from the company or the agency but experts who can say the model is or isn't in compliance with these stated safety thresholds and these percentages of performance on question X or Y can you send me that information we will do that um would you be qualified to uh to to uh if we promulgated those rules to administer those rules I love my current job cool are there people out there that would be qualified we'd be happy to send you recommendations for people out there yes okay you're making a lot of money do you I make no I paid enough for health insurance I have no equity in open AI really yeah that's interesting you need a lawyer I need a what you need a lawyer or an agent I I'm doing this because I love it thank you Mr chairman thanks Senator Kennedy uh senator hirono thank you Mr chairman chairman listening to to all of your testifying thank you very much for being here clearly AI truly is a game-changing tool and uh we need to get the regulation of this tool right because my staff for example asks AI it might have been gpt4 it might have been I don't know one of the other entities to create a song that my favorite band BTS a favorite a song that they would sing somebody else's song but you know neither of the artists were involved in creating what sounded like a really genuine song so you can do a lot we also ask can can there be a speech created talking about the the Supreme Court decision in Dobbs and the chaos that it created using my voice my kind of voice and it created a speech that was really good it almost made me think about you know what do I need my staff for so don't worry that's not very nervous laughter behind you oh their jobs are safe but there's so much that can be done and one of the things that you mentioned Mr May Altman that intrigued me was you said gpd4 can refuse harmful requests so you must have put some thought into how your system if I can call it that can refuse harmful requests what what do you consider a harmful request you can just keep it short yeah uh I'll give a few examples uh one would be about violent content another would be about content that's encouraging self-harm another's adult content not that we think adult content is inherently harmful but there's things that could be associated with that that we cannot reliably enough differentiate so we refuse all of it so those are some of the more obvious harmful kinds of of information but in the election context for for example I saw a picture of a former president Trump being arrested by NY PD and that went viral I don't know is that considered harmful I've seen all kinds of statements attributed to any one of us that could be put out there that may not be that may not rise to your level of harmful content but there you have it so two of two of you said that we should have a licensing scheme I can't Envision or imagine right now what kind of our licensing scheme we would be able to create to pretty much regulate the vastness of of the this game to changing tools so are you thinking of an FTC kind of a system an FCC kind of a system what do the two of you even Envision as a potential licensing scheme that would provide the kind of guard Wheels that we need to protect our literally our country from harmful content to touch on the first part of what what you said there are things besides uh you know should this content be generated or not that I think are also important so that image that you mentioned was generated I think it'd be a great policy to say generated images need to be made clear in all contexts that they were generated and you know then we still have the image out there but it's we're at least requiring people to say this was a generated image to make that where I think the licensing scheme comes in is uh not with not for what these models are capable of today because as you pointed out you don't need a new licensing agency to do that but as we as we head and you know this may take a long time I'm not sure as we head towards artificial general intelligence and the impact that will have and the power of that technology I think we need to treat that as seriously as we treat other very powerful Technologies and that's where I personally think we need such a such a scheme I agree and that is why by the time we're talking about AGI we're talking about uh major harms that can occur through the use of AGI so um Professor Marcus having what kind of a regulatory scheme would you envision and what and we can't just come up with something you know that is going to be of uh take care of the issues that will arise in the future especially with AGI so what is what kind of a scheme would you contemplate well first if I can rewind just a moment um I think you really put your finger on the central scientific issue in terms of the challenges in building artificial intelligence we don't know how to build a system that understands harm in the full breadth of its meaning so what we do right now is We Gather examples and we say is this like the examples that we have labeled before but that's not broad enough and so I thought you're questioning beautifully outlined the challenge that AI itself has to face in order to to Really deal with this we want AI itself to understand harm and that may require new technology so I think that's very important on this second part of your question the model that I trend they gravitate towards but I am not an expert here is the FDA at least as part of it in terms of you have to make a safety case and say why the benefits out weigh the Harms in order to get that license probably we need elements of multiple agencies I'm not an expert there but I think that the safety case part of it is incredibly important you have to be able to have external reviewers that are scientifically qualified look at this and say you have you addressed enough so I'll just give one specific example Auto GPT frightens me that's not something that open AI made but something that open AI did make call called chat GPD plugins led a few weeks later to some Building open source software called Auto GPT and what Auto GPT does is it allows systems to access source code access the internet and so forth and there are a lot of potential let's say cyber security risks there there should be an external agency that says well we need to be reassured if you're going to release this product that there aren't going to be cyber security problems or there are ways of addressing it so Professor I am running model is the the use model similar to what the EU has come up with but the vas vastness of AI and the complexities involved I think would require more than looking at the use use of it and I think that based on what I'm hearing today don't you think that that uh we're probably going to need to do a heck of a lot more than to focus on what use it as being AI is being used for for example you can ask AI to come up with a funny joke or something but you can use the same you can ask the same AI tool to generate something that is like an election fraud kind of a situation so I don't know how you will make a determination based on where you're going with the use model how to distinguish those kinds of uses of this tool so I think that if we're going to go toward a licensing kind of a scheme we're going to need to put a lot of thought into how we're going to come up with an appropriate scheme that is going to provide the kind of future reference that we need to put in place so I I thank all of you for coming in and providing further food for thought thank you Mr chairman thanks very much Senator hirono uh Senator Padilla thank you Mr chairman I appreciate the flexibility as I've been uh back and forth to uh between this committee and Homeland Security committee where there's a hearing going on right now on the use of AI in government so it's AI day on the hill or at least the Senate apparently now for folks watching at home if you never thought about AI until the recent emergence of generative AI tools the developments in this space may feel like they've just happened all of a sudden but the fact of the matter is Mr chairs that they haven't AI is not new not for government not for business not for public not for the public in fact the public uses AI all the time and just for folks to be able to relate want to offer the example of anybody with a smartphone uh many features on your device leverage AI including suggested replies right over text messaging or even to email autocorrect features including but not limited to spelling in her email and text applications so I'm frankly excited to explore how we can facilitate positive AI Innovation that benefits Society while addressing some of the already known harms and biases that stem from the development and use of the tools today now with language models becoming increasingly ubiquitous I want to make sure that there's a focus on ensuring Equitable treatment of diverse demographic groups my understanding is that most research in to evaluating and mitigating fairness harms has been concentrated on the English language while non-english languages have received comparatively little attention or investment and we've seen this problem before and I'll tell you why I raised this social media companies for example have not adequately invested in content moderation tools and resources for their non-english uh in in non-english language and I share this not just out of concern for non-us-based users but so many us-based users prefer a language other than English in their communication so I'm deeply concerned about repeating social media's failure in AI tools and applications question Mr Altman and Miss Montgomery how are open Ai and IBM ensuring Language and Cultural inclusivity that they're in their uh large language models and it's even an area of focus in the development of your products so bias and equity in technology is a focus of ours and always has been I think diversity in terms of the development of the tools in terms of their deployment so having diverse people that are actually training those tools considering the downstream effects as well we're also very cautious uh very aware of the fact that we can't just be articulating and calling for these types of things without having the tools and the technology to test for bias and to apply governance across the life cycle of AI so we were one of the first teams and companies to put tool kits on the market deploy them contribute them to open source that will do things like help to address you know be the technical aspects in which we help to address issues like bias can you speak just for a second specifically to language inclusivity yeah I mean language so we don't have a consumer platform but we are very actively involved with ensuring that the technology we hope to deploy in the large language models that we use in helping our clients to deploy technology is focused on and available in many languages thank you the shop we think this is really important one example is that we worked with the government of Iceland which is a language with fewer speakers than many of the languages that are well represented on the internet to ensure that their language was included in our model and we've had many similar conversations and I look forward to many similar Partnerships with lower resource languages to get them into our models gpt4 is uh unlike previous models of ours which were good at English and not very good at other languages uh now pretty good at a large number of languages you can go pretty far down the list ranked by number of speakers and still get good performance but for these very small languages we're excited about custom Partnerships to include that language into our model run and the part of the question you asked about values and making sure that cultures are included we're equally focused on that excited to work with people who have particular data sets and to work to collect a representative set of values from around the world to draw these wide bounds of what the system can do I also appreciate what you said about the the benefits of these systems and wanting to make sure we get those to as wide of a group as possible I think this will these systems will have lots of positive impact on a lot of people but in particular underrepresented historically underpresented groups in technology people who have not had as much technology around the world this technology seems like it can be a big lift up and I know my question was specific to language inclusivity but uh glad there's agreement on the broader uh commitment to uh diversity and inclusion and I'll just give a couple more reasons why they think it's so critical you know the largest actors in this space can afford the massive amount of data the computing power and they have the financial resources necessary to develop complex AI systems but in this space we haven't seen from a Workforce standpoint the racial and gender diversity reflective of the United States of America and we risk if we're not thoughtful about it uh contributing to the development of tools and approaches that only exacerbate uh the bias and inequities that exist in our society so a lot of follow-up work to do there in my time remaining I do want to ask one more question this committee and the public are right to pay attention to the emergence of generative AI this technology has a different opportunity and a risk profile than other AI tools and these applications have felt very tangible for the public due to the nature of the user interface and the outputs that they produce but I don't think we should lose that of the broader AI ecosystem as we consider ai's broader impact on society as well as the design of appropriate safeguards so miss Montgomery in your testimony uh as you noted AI is not you can you highlight some of the different applications that the public and policy makers should also keep in mind as we consider possible regulations yeah I mean I think the generative AI systems that are available today are creating new issues that neces that need to be studied new issues around the potential to generate content that could be extremely misleading deceptive and alike so those issues absolutely need to be studied but we shouldn't also ignore the fact that AI is a tool it's been around for a long time it has capabilities Beyond just generative capabilities and again that's why I think going back to this approach where we're regulating AI where it's touching people and Society is a really important way to address it thank you Mr chair thanks Senator Padilla uh Senator Booker is next but I think he's going to defer to senator ossoff because Senator also offers a very big deal I don't know I have a meeting at noon and I'm grateful to you Senator Booker for yielding your time you are as always brilliant and handsome and uh thank you to the panelists for joining us thank you to the subcommittee leadership for opening us up to all committee members if we're going to contemplate a regulatory framework we're gonna have to Define what it is that we're regulating so uh you know Mr Alban any such law will have to include a section that defines the scope of regulated activities Technologies tools products just take a stab at it yeah thanks for asking Senator also I think I think it's super important I think there are very different levels here and I think it's important that any any new approach any new law does not stop the Innovation from happening with smaller companies open source models researchers that are doing work at a smaller scale uh that's a wonderful part of this ecosystem and of America we don't want to slow that down there still may need to be some rules there but I think we could draw a line at systems that need to be licensed in a very intense way the easiest way to do it I'm not sure if it's the best but the easiest would be to talk about the amount of compute that goes into such a model so we could divide you know we could Define a threshold of compute and it'll have to go it'll have to change it could go up or down I could down as we discover more efficient algorithms that says above this amount of compute you are in this regime what I would prefer it's hard to do but I think more accurate is to Define some capability thresholds and say a model that can do things X Y and Z up to all to decide that's now in this licensing regime but models that are less capable you know we don't want to stop our open source Community we don't want to stop individual resources we don't want to stop new startups can proceed you know with a different framework thank you as concisely as you can please state which capabilities you'd propose we'd consider for the purposes of this definition I would love rather than to do that off the cuff to follow up with your office with like well perhaps openings opine understanding that you're just responding uh and you're not making law all right in the spirit of just a pining um I think a model that can uh persuade manipulate influence person's Behavior or a person's beliefs that would be a good threshold I think a model that could help create novel biological agents would be a great threshold things like that I want to talk about the predictive capabilities of a technology and we're gonna have to think about a lot of very complicated constitutional questions that arise from it with with massive data sets the integrity and accuracy with which such technology can predict future human behaviors potentially pretty significant at the individual level correct I think we don't know the answer to that for sure but let's say it can at least have some impact there okay so we may be confronted by situations where for example a law enforcement agency deploying such technology seeks some kind of judicial consent to execute a search or to take some other police action on the basis of a modeled prediction about some individual's Behavior uh but that's very different from the kind of evidentiary predicate that normally police would take to a judge in order to get a warrant talk me through how you think about that issue yeah I think it's very important that we continue to understand that these are tools that humans use to make human judgments and that we don't take away human judgment I don't think that people should be prosecuted based off of the output of an AI system for example we have no uh National Privacy Law the Europe has has rolled one out to mixed reviews do you think we need one I think it'd be good and what would be the qualities or purposes of such a law that you think would make the most sense based on your experience again this is very far out of Meyer of expertise I think there's many many people that could that are privacy experts that could weigh on what a law needs I'd still like I'd still like you to weigh in um I mean I think a minimum is that users should be able to to sort of opt out from having their data used by companies like ours or the social media companies it should be easy to delete your data I think those are it should but the thing that I think is important from my perspective running an AI company is that if you don't want your data used for training these systems uh you have the right to do that so let's think about how that will be practically implemented I mean uh as I understand it your tool and certainly similar tools one of the inputs will be um scraping for lack of a better word data off of the open web right as a low-cost way of of gathering information and there's a vast amount of information out there about all of us how would such a restriction on the access or use or analysis of such data be practically implemented so I was speaking about something a little bit different which is the data that someone generates the questions they ask our system things that they input their training on that data that's on the public web that's accessible even if we don't train on that the models can certainly link out to it so that was not what I was referring to I think that you know there's ways to have your data or there should be more ways to have your data taken down from the public web but certainly models with web browsing capabilities will be able to search the web and Link out to it when you think about implementing a safety or a regulatory regime to constrain such software and to mitigate some risk is your view that the federal government would make laws such that certain capabilities or functionalities themselves are forbidden in potential in other words one cannot uh deploy or execute code capable of X yes or is it the act itself X only when actually executed well I think both I'm a Believer in defense in depth I think that there should be limits on what a deployed model is capable of and then what it actually does too how are you thinking about how kids use your product we well you have to be I mean you have to be 18 or up or have your parents permission at 13 and up to use a product but we understand that people get around those safeguards all the time and so what we try to do is just design a safe product and there are decisions that we make that we would allow if we knew only adults were using it that we just don't allow in the product because we know children will use it some way or other two in particular given how much these systems are being used in education we like want to be aware that that's happening I think what and and Senator Blumenthal has done extensive work investigating this what we've seen repeatedly is that companies whose revenues depend upon volume of use screen time intensity of use design these systems in order to maximize the engagement of all users including children with with perverse results in many cases and what I would humbly advise you is that you get way ahead of this issue the safety for children of your product or I think you're going to find that Senator Blumenthal Senator Holly others on the subcommittee and I um are will look very harshly on the deployment of technology that harms children we couldn't agree more I think we're out of time but I'm happy to talk about that if I can respond go ahead well it's up to the chairman okay um I first of all I think we try to design systems that do not maximize for engagement in fact we're so short on gpus the less people use our products the better but we're not an Advertising based model we're not trying to get people to use it more and more um and I think that's that's a different shape than ad supported social media second uh these systems do have the capability to to influence in obvious and in very nuanced ways and I think that's particularly important for the safety of children but that will that will impact all of us one of the things that we'll do ourselves uh regulation or not but I think a regulatory approach would be good for also is requirements about how the values of these systems are set and how these systems respond to questions that can cause influence so we'd love to partner with you couldn't agree more on the importance thank you Mr chairman for the record I just want to say that the senator from Georgia is also very handsome and Brilliant too but I will uh allow that comment to stand with without objection without objection okay um Mr chairman are now recognized thank you very much thank you it's nice that we finally got down to the bald guys down here at the end um I just want to thank you both this has been one of the best hearings I've had this Congress and uh just a testimony to you to seeing uh the the challenges and the opportunities that AI presents so I appreciate you both I want to just jump in I think very broadly and then I'll get a little more narrow uh Sam you said very broadly technology has been moving like this and we are a lot of people have been talking about regulation and so I use the example of the automobile what an extraordinary uh piece of technology I mean New York City did not know what to do with horse manure they were having crises forming commissions and the automobile comes along ends that problem but at the same time we have tens of thousands of people dying on highways every day we have emissions crises and the like there are multiple federal agencies multiple federal agencies that were created uh or are specifically focused on regulating cars um and and so this idea that this equally transforming technology is coming and for Congress to do nothing which is not what anybody hears is is uh calling for little or nothing is is obviously unacceptable uh I really appreciate uh Senator Welsh and I have been going back and forth uh during this hearing and him and Bennett have a bill talking about trying to regulate in this space not doing so for uh social media uh has been I think very destructive and allowed a lot of things uh to go on that are really causing a lot of harm and so the question is is what kind of Regulation you all have spoken about to a lot of my colleagues um and I and I want to say that Miss Montgomery and I have to give full disclosure I'm the child of two IBM parents um uh but I I you know you talked about uh defining the highest risk uses we don't know all of them we really don't we can't see where this is going uh regulating at the point of risk and you you sort of called not for an agency and I think when you when somebody else asks you to specify because you don't want to slow things down we should build on what we have in place but you can Envision that we can try to work on two different ways that ultimately a specific like we have in uh in cars EPA Nitza the federal motor car carrier safety administration all of these things you can imagine something specific that is uh as Mr Marcus points out a Nimble agency that could do monitoring other things you could imagine the need for something like that correct oh absolutely yeah and and so uh just for the record then in addition to trying to regulate with what we have now you would encourage Congress and my colleague Senator Welsh to move forward in trying to figure out the right tailored agency to deal with what we know and perhaps things that might come up in the future I would encourage Congress to make sure it understands the technology has the skills and resources in place to impose regulatory requirements on the uses of the technology and to understand emerging risks as well so yes yeah Mr Marcus there's no way no way to put this genie in the bottle globally this is It's exploding I appreciate your thoughts and I shared some with my staff about your ideas of what the international context is but there's there's no way to stop this moving forward so with that understanding just building on what what Miss Montgomery said what kind of encouragement do you have as specifically as possible to forming an agency to using current rules and regulations can you just put some clarity on what you've already stated let me just insert there are more Genies yet to come from more bottles some Genies are already out but we don't have machines that can really for example self-improve themselves we don't really have machines that have self-awareness and we might not ever want to go there so there are other Genies to be concerned about onto the main part of your question I think that we need to have some International meetings very quickly with people who have expertise in how you grow agencies in the history of growing agencies we need to do that in the federal level we need to do that in the international level I'll just emphasize one thing I haven't as much as I would like to which is that I think science has to be a really important part of it and I'll give an example we've talked about misinformation we don't really have the tools right now to detect and label misinformation with nutrition labels that we would like to we have to build new technologies for that we don't really have tools yet to detect a wide uptick in cyber crime probably we probably need new tools there we need science to probably help us to figure out what we need to build and also what it is that we need to have transparency around understood understood Sam just go to you uh for the little bit of time I have left real quick um first of all you're a bit of a unicorn when I sat down with you first could you explain why non-profit in other words you're you're you're you're not looking this and you've even capped the vce people just really quickly I want folks to understand that we started as a non-profit uh really focused on how this technology was going to be built at the time it was very outside the Overton window that something like AGI was even possible that's that shifted a lot um we didn't know at the time how important scale was going to be but we did know that we wanted to build this um with Humanity's best interests at heart and a belief that this technology could if it goes the way we we want if we can do some of those things for Professor Marcus mentioned uh really deeply transformed the world and we wanted to be as much of a force for getting to a positive I'm going to interrupt you I think that's all good I hope more of that gets out on the record the second part of my question as well um I found it fascinating uh but are you ever gonna for a revenue model for return on your investors are you ever going to do ads or something like that I wouldn't say never I don't think like I think there may be people that we want to offer services to and there's no other model that works but I really like having a subscription-based model uh we have API developers pay us and we have chat okay so that then can I just jump real quickly one of my biggest concerns about this space is what I've already seen in the space of uh web 2 web 3 is this massive corporate concentration it is really terrifying to see how few companies now control and affect the lives of so many of us and these companies are getting bigger and more powerful and I see you know open AI back by Microsoft anthropic is backed by Google Google has its own in-house products We Know bar so I'm really worried about that and I'm wondering uh if Sam you can give me a quick uh acknowledgment are you worried about the corporate concentration in this space and what effect it might have uh um uh in the associated risks perhaps with Market concentration in Ai and then Mr Market Marcus can you answer that as well I think there will be many people that develop models uh what's happening on the open source Community is amazing but there will be a relatively small number of providers that can make models at the at the church um I think there is benefits and danger to that because we're talking about all the dangers with AI the fewer of us that you really have to keep a careful eye on on the absolute like bleeding edge of capabilities there's benefits there but then I think there needs to be enough in their will because there's so much value that consumers have choice that we have different ideas Mr Marcus real quick there is a real risk of a kind of technical technocracy combined with oligarchy where a small number of companies influence people's beliefs through the nature of these systems again I put something in the wall in the record about the Wall Street Journal about how these systems can subtly shape our beliefs and that's enormous influence on how we live our lives and having a small number of players do that with data that we don't even know about that scares me Sam I'm sorry one more thing I wanted to add one thing that I think is very important is that that what these systems get aligned to whose values what those bounds are that that is somehow set by society as a whole by governments as a whole and so creating that data set the Align that our alignment data set it could be you know an AI Constitution whatever it is that that has got to come very broadly from society thank you very much Miss Jeremiah Thomas expired and I guess the best for last thank you Senator Booker Senator well first of all I want to thank you Senator Blumenthal and you Senator Hawley this has been a tremendous hearing uh senators are noted for their short attention spans but I've sat through this entire hearing and enjoyed every minute of it you have one of our longer attention spans in the United States to your great credit well we've had good Witnesses and it's an incredibly important issue and here's just I don't all the questions I have have been asked really but here's a kind of a takeaway in what I think is the major question that we're going to have to answer as a congress number one you're here because AI is this extraordinary new technology that everyone says can be transformative as much as the printing press number two is really unknown what's going to happen but there's a big fear you've expressed to all of you about what Bad actors can do and will do if there's no rules of the road uh number three as a member who served in the house and now in the Senate I've come to the conclusion that it's impossible for Congress to keep up with the speed of Technology and there have been concerns expressed uh and so about social media and now about a AI that relate to fundamental privacy rights bias rights intellectual property uh the spread of disinformation which in many ways for me is the biggest threat because that goes to the core of our capacity for self-governing uh there's the economic transformation which can be profound through safety concerns and and I've come to the conclusion that we absolutely have to have an agency what it's scope of Engagement is it has to be defined by us but I believe that unless we have an agency that is going to address these questions from social media in AI we really don't have much of a defense against the bad stuff and the bad stuff will come so uh last year I introduced in the house side and Senator Bennett did incentives it was the end of the year a digital commission act and we're going to be reintroducing that this year and the two things that I want to ask one you've somewhat answered because I think two of the three of you have said you think we do need an independent commission you know and Congress establishing an independent commission when railroads were running rampant over the interest of farmers when Wall Street had no rules of the road and we had the SEC and I think we're at that point now but what the commission does would have to be defined and circumscribed but also there's always a question about the use of regulatory Authority and the recognition that it can be used for good JD Vance actually mentioned that when we were considering his and Senator Brown's Bill about railroads in that event in East Palestine regulation for the public health but there's also a legitimate concern about regulation getting in the way of things being too cumbersome and being a negative influence so a two of the three of you have said you think we do need an agency uh what are some of the Perils of an agency that we would have to be mindful of in order to make certain that its goals of protecting many of those interests I just mentioned privacy bias intellectual property disinformation would be the winners and not the losers and I'll start with you Mr Altman thank you Senator uh one I think America has got to continue to lead this happened in America I'm very proud that it happened in America by the way I I think that's right and that's why I'd be much more confident if we had our agency as opposed to got involved in international discussions ultimately you want the rules of the road but I think if we lead and get rules of the road that work for us that is probably a more effective way to proceed I I I personally believe there's a way to do both and I think it is important to have the global view on this because this technology will impact Americans and all of us wherever it's developed but I think we want America to lead we want we want so get to the perils issue though because I know well that's one I mean that is apparel which is you slow down American industry in such a way that China or somebody else makes faster progress a second and I think this can happen with like the regulatory pressure should be on us it should be on Google it should be on the other small set of people in the lead the most we don't want to slow down smaller startups we don't want to slow down uh open source efforts we still need them to comply with things they can still you can still cause great harm with a smaller model but leaving the room and the space for new ideas and new companies uh and independent researchers to do their work and not put in a regulatory burden to say a company like us could handle but a smaller one couldn't I think that's another Peril and it's clearly a way that regulation has gone Mr Marcus or Professor Marcus the the other obvious Peril is regulatory capture if we make it as appear as if we are doing something but it's more like green washing and nothing really happens we just keep out the little players because we put so much burden that only the big players can do it so there are also those kinds of perils I fully agree with everything that that Mr Altman said and I would add that to the list Montgomery things I would add to those does the risk of not holding companies accountable for the harms that they're causing today right so we talk about misinformation in electoral systems so no agency or no agency we need to hold companies responsible today and accountable for AI that they're deploying that disseminates misinformation on things like elections and where the where the risk you know regulatory agency would do a lot of the things that Senator Graham was talking about you know you don't build a nuclear reactor without getting a license you don't build an AI system without getting a license that gets tested independently I think it's a great analogy we need both pre-deployment pre-deployment and post deployment okay thank you all very much I yield back Mr chairman thanks thanks Senator Welsh let me ask a few more questions you've all been very very patient and the turnout today which is beyond our subcommittee I think reflects both your value in what you're contributing as well as the interest in this topic uh there are a number of subjects that we haven't covered at all but one was uh just alluded to I Professor Marcus which is the monopolization danger the dominance of markets that excludes new competition and thereby inhibits or prevents Innovation and invention which we have seen in social media as well as some of the old Industries Airlines Automobiles and others where consolidation has narrowed competition and so uh I think we need to to focus on kind of an old area of antitrust which dates more than a century still inadequate to deal with the challenges we have right now in our economy and certainly we need to be mindful of the way that rules can enable the big guys to get bigger and exclude Innovation and competition and responsible good guys such as are represented in this industry right now we haven't dealt with National Security there are huge implications for National Security I will tell you as a member of the armed service committee uh classified briefings on this issue have abounded and the threats that are posed by some of our adversaries China has been mentioned here but the sources of threats to this nation in this space are very real and Urgent uh we're not going to deal with them today but we do need to deal with them and we will hopefully in this committee and then uh on the issue of a new agency you know I've been doing this stuff for a while I was attorney general Connecticut for 20 years I was a federal prosecutor the U.S attorney most of my career has been in enforcement and I will tell you something you can create 10 new agencies but if you don't give them the resources and I'm talking not just about dollars I'm talking about scientific expertise you guys will run circles around them and it isn't just the the models or the generative AI that will run models around run circles around them but it is the scientists in your company for every success story in government regulation you can think of five failures that's true of the FDA it's true of the iaea it's true of the SEC it's true of the whole alphabet list of government agencies and I hope our experience here will be different but the Pandora's Box requires more than just the words or the concepts licensing new agency there's some real hard decision making as as Montgomery has alluded to about how to frame the rules to fit the risk first Do no harm make it effective make it enforceable make it real I think we need to Grapple with the the hard questions here that you know frankly this initial hearing I think is raised very successfully but not answered and I I thank our colleagues who have participated and and made these uh very creative suggestions I'm very interested in uh enforcement I you know literally 15 years ago I think abdicated abolishing section 230. what's old is New Again you know now people are talking about abolishing section 230 back then it was considered completely unrealistic but uh enforcement really does matter I want to ask uh Mr Altman because of the the Privacy issue and you've suggested uh that you have an interest in protecting the privacy of the data that may come to you or be available how do you What specific steps you take uh to protect privacy uh one is that we don't train on any data submitted to our API so if you're a business customer of ours and submit data we don't train it at all we do retain it for 30 days solely for the purpose of trust and safety enforcement um but that's different than training and I if you use chat GPT you can opt out of us training on your data you can also delete your conversation history or your whole account um Miss Montgomery I know you don't deal directly with consumers but do you take steps to protect privacy as well absolutely and we even filter our large language models for Content that includes personal information that may have been pulled from public data sets as well so we apply additional level of filtering um Professor Marcus you made reference to self-awareness self-learning uh already we're talking about the potential for jailbreaks um how soon do you think that new kind of generative AI will be usable will be practical new AI that is self-aware and so forth where yes I mean I have no idea on that one I think we don't really understand what self-awareness is and so it's hard to put a date on it in terms of self-improvement there's some modest self-improvement in current systems but one could imagine a lot more and that could happen in two years it could happen in 20 years the basic paradigms that haven't been invented yet some of them we might want to discourage but it's a bit hard to put timelines on them and just going back to enforcement for one second one thing that is absolutely Paramount I think is far greater transparency about what the models are and what the data are that doesn't necessarily mean everybody in the general public has to know exactly what's in one of these systems but I think it means that there needs to be some enforcement arm that can look at these systems can look at the data can perform tests and so forth um let me ask you uh all of you uh I think there has been a reference to um elections and banning um outputs involving elections are there other areas where you think what are the what are the other high risk or highest risk areas where you would either ban or establish especially strict rules Miss Montgomery the space around misinformation I think is hugely important one and coming back to the points of transparency you know knowing what content was generated by AI is going to be a really critical area that we need to address any others I think medical misinformation is something to really worry about we have systems that hallucinate things they're going to hallucinate medical advice some of the advice they'll give is good some of it's bad we need really tight regulation around that same with psychiatric advice people using these things as as kind of erzot's therapists I think we need to be very concerned about that I think we need to be concerned about internet access for these tools when they can start making requests both of people and and internet things is probably okay if they just do search but as they do more intrusive things on the internet like do we want them to be able to order equipment or order chemistry and so forth so as they as we Empower these systems more by giving them internet access I think we need to be concerned about that and then we've hardly talked at all about long-term risk Sam alluded to it briefly I don't think that's where we are right now but as we start to approach machines that have a larger footprint on the world Beyond just having a conversation we need to worry about that and think about how we're going to rank regulate that and monitor it and so forth in a sense we've been talking about bad guys or um certain Bad actors manipulating AI to do harm manipulating people and manipulating people but also generative AI can manipulate the manipulators it it can I mean there's there's many layers of manipulation that are possible and I think we don't yet really understand the consequences Dan Dennett just sent me a manuscript last night that will be in the Atlantic in a few days on what he calls counterfeit people it's a wonderful metaphor these systems are almost like counterfeit people and we don't really honestly understand what the consequence of that is they're not perfectly human like yet but they're good enough to fool a lot of the people a lot of the time and that introduces lots of problems for example cyber crime and how people might try to manipulate markets and so forth so it's a serious concern in my opening I suggested three principles transparency accountability and limits on use would you agree that those are a good starting point is Montgomery 100 and as you also mentioned industry shouldn't wait for congress that's what we're doing here at IBM there's no reason that absolutely wait for congress yep Professor Marcus I think those three would be a great start I mean there are there are things like the White House Bill of Rights for example that show I think a large consensus the UNESCO guidelines and so forth so a large consensus around what it is we need and the real question is definitely now how are we going to put some teeth in it try to make these things actually enforce so for example we don't have transparency yet we all know we want it but we're not doing enough to enforce it Mr Altman I certainly agree that those are important points I would add that and Professor Marcus touched on this I would add that as we we spend most of the time today on current risks and I think that's appropriate and I'm very glad we have done it as these systems do become more capable and I'm not sure how far away that is but maybe not not super far I think it's important that we also spend time talking about how we're going to confront those challenges I mean talk to you privately you know how much I care I agreed that you care deeply and intensely but also that Prospect of increased danger or risk resulting from even more complex and capable AI mechanisms certainly may be closer than a lot of people appreciate let me just add for the record that I'm sitting next to Sam closer than I've ever sat to him except once before in my life and that his sincerity in talking about those fears is very apparent physically in a way that just doesn't communicate on the television screen thank you communicates from here thank you Senator Hawley thank you again Mr chairman for a great hearing thanks to the witnesses so I've been keeping a little list here of the potential downsides or harms risks of generative AI even in its current form let's just run through a loss of jobs and this isn't speculative I think your company Miss Montgomery has announced that it's it's potentially laying off 7 800 people a third of your non-consumer facing Workforce for because of AI so loss of jobs invasion of privacy personal privacy on a scale we've never before seen manipulation of personal Behavior manipulation of personal opinions and potentially the degradation of free elections in America did I miss anything I mean this is this is quite a list I noticed that an Eclectic group of about a thousand technology and AI leaders everybody from Andrew Yang to Elon Musk recently called for a six-month moratorium on any further AI development were they right do you join those calls are you right to do that should we should we pause for six months characterization's not quite correct um I actually signed that letter about 27 000 people signed it um it did not call for a ban on all AI research it only caught in nor on all AI but only on a very specific thing which would be systems like gpt5 um every other piece of research that's ever been done it was actually supportive or neutral about and specifically called for more AI sorry specifically called for more research on trustworthy and safe AI so you think just so you think that we should take a moratorium a six-month moratorium or more on anything beyond chat gpt4 I took the letter what is the famous phrase uh spiritually not literally what was the famous phrase um well I'm asking for your opinion now though my opinion is that the moratorium that we should focus on is actually deployment until we have good safety cases I don don't know that we need to pause that particular project but I do think it's emphasis on focusing more on AI safety on trustworthy reliable AI is that exactly right deployment means not making it available to public yeah my concern is about things that are deployed at a scale of let's say 100 million people without any external review I think that we should think very carefully about doing that what about you Mr Altman do you agree with that would you would you pause any further development for six months or longer uh so first of all we after we finish training gpt4 we waited more than six months to deploy it um we are not currently training what will be gpd5 we don't have plans to do it in the next six months but I think the frame of the letter is wrong what matters is audits red teaming safety standards that a model needs to pass before training if we pause for six months then I'm not what we sure sure what we do then do we pause for another six do we kind of come up with some rules then the standards that we have developed and that we've used for gpd4 deployment uh we want to build on those but we think that's the right direction uh not a calendar clock pause there may be times I expect there will be times when we find something that we don't understand and we really do need to take a pause but we don't see that yet never mind all the benefits you don't see what yeah you're comfortable with all of the potential ramifications from the current existing technique I'm sorry we don't see the reasons to not train a new one for deploying as I mentioned I think there's all sorts of risky behavior and there's limits we put we have to pull things back sometimes add new ones I meant we don't see something that would stop us from training the next model uh where we'd be so worried that we'd create something dangerous even in that process let alone the deployment what about you miss Montgomery I think we need to use the time to prioritize ethics and responsible technology as opposed to posing development well wouldn't a pause and development help the development of protocols for safety standards and ethics I'm not sure how practical it is to pause but we absolutely should be prioritizing safety protocols okay the the point about practicality leads me to this I'm interested in this talk about an agency and you know maybe that would work although having seen how agencies work in this government they usually get captured by the interests that they're supposed to regulate they usually get controlled by the people who they're supposed to be watching I mean that's just been our history for 100 years maybe this agency would be different I have a little different idea why don't we just let people sue you why don't we just make you liable in court we knew that we know how to do that we can pass the statute we can create a federal right of action that will allow private individuals who are harmed by this technology to get into court and to bring evidence into court and it can be anybody I mean we want to talk about crowdsourcing we'll just open the courthouse doors will Define a broad right of action private right of action private citizens be class actions we'll just open it up we'll allow people to go into court we'll allow them present evidence they say that they were harmed by they were given medical misinformation they were given election of misinformation whatever why not do that Mr Altman I mean please forgive my ignorance can't can't people sue us because well you're not protection by protected by section 230 but there's not currently a I don't think a federal right of action private right of action that says that if you are harmed by generative AI technology we will guarantee you the ability to get into court oh well I think there's like a lot of other laws where if you know technology harms you uh there's standards that we could be sued under unless I'm really misunderstanding how things work uh if the question is are more are clearer laws about the specifics that this technology and consumer protection is a good thing I would say definitely yes the laws that we have today were designed long before we had artificial intelligence and I do not think they give us enough coverage uh the plan that you propose I think is a hypothetical would certainly make a lot of lawyers wealthy but I think it would be too slow to affect a lot of the things that we care about and there are gaps in the law for example we don't really wait you think it'd be slower than Congress yes I do in some ways really litigation can take a decade or more oh I think the threat litigation is a powerful tool I mean how would IBM like to be 100 million dollars in no way asking to take litigation off the table among the tools but I think for example if I can uh continue um we there are areas like copyright where we don't really have laws we don't really have a way of thinking about wholesale misinformation as opposed to individual pieces of it where say a foreign actor might make billions of pieces of misinformation or a local actor we have some laws around Market manipulation we could apply but we get in a lot of situations where we don't really know which laws apply there would be loopholes this system is really not thought through in fact we don't even know that 230 does or does not apply here as far as I know I think that that's something a lot of people speculated about this afternoon but it's not something we could fix that well the question is how oh easy you just you just it would be easy for us to say that section 230 doesn't apply to generative AI yeah Miss Montgomery a duty of care which I think fits the idea of a private right of action now that's exactly right and also AI is not a shield right so so if a company discriminates in granting credit for example or in the hiring process the by virtue of the fact that they relied too significantly on an AI tool they're responsible for that today regardless of whether they used a tool or a human to make that decision I'm going to turn to Senator Booker for some final questions but I just uh want to make a quick Point here on the on the issue of the moratorium I think we need to be careful The World Won't Wait the rest of the global scientific Community isn't going to pause we have adversaries that are moving ahead and sticking our head in the sand is not the answer safeguards and protections yes but a flat stop sign sticking our head in the sand I would be very very worried without militating for any sort of pause I would just again emphasize there is a difference between research which surely we need to do to keep Pace with our foreign Rivals and deployment at really massive scale you know you could deploy things at a scale of a million people or 10 million people but not a hundred million people or a billion people and if there are risks you might find them out sooner and be able to close the barn doors before the horses leave rather than after Senator Booker yeah I I just there will be no pause I mean there's no enforcement body to force appall it's just not not going to happen it's nice to call for it for any just reasons or whatsoever but I'm just forgive me for sounding skeptical nobody's pausing this thing is crazy I would agree and I don't think it's a realistic thing in the world the reason I personally signed the letter was to call attention to how serious the problems were and to emphasize spending more of our efforts on trustworthy and safe AI rather than just making a bigger version of something we already know to be unreliable yeah so I'm I'm uh futurist I love the exciting about the future and I guess there's a famous question uh if you couldn't control for your race your gender where you would land on the planet Earth or what time in humanity would you want to be born everyone would say right now it's the it's still the best time to be alive because of Technology Innovation and everything and I'm excited about what the future holds but the destructiveness that I've also seen as a person that's seen the transformative Technologies of uh of of a lot of the Technologies of the last 25 years is is what really concerns me and one of the things especially with um companies that are designed to want to keep my attention on screens and I'm not just talking about New Media a 24-hour cable news is a great example of people that want to keep your eyes on screens I have a lot of concerns about the corporate intention and and Sam this is again why I find your story so fascinating to me and your values that I believe in from our conversations so compelling to me but but perhaps in that I really want to just explore what happens when these companies that are already controlling so much of our lives a lot has been written about the Fang companies what happens when they are the ones that are dominating this technology as they did before so Professor Marcus does that have any concern the role that corporate power corporate concentrate creation has in this realm that a few companies might might control this whole area I radically change the shape of my own life in the last few months and it was because of what happened with Microsoft releasing Sydney and it didn't go the way I thought it would in one way it did which as I anticipated the hallucinations I wrote an essay which I have in the appendix What to Expect When You're Expecting gpt4 and I said that it would still be a good tool for misinformation that it would still have trouble with physical reasoning psychological reasoning that it would hallucinate and then Along Came Sydney and the initial press reports were quite favorable and then there was the famous article by Kevin Roos in which it recommended he get a divorce and I had seen Tay and I had seen Galactica from meta and those had been pulled after they had problems and Sydney clearly had problems what I would have done had I run Microsoft which clearly I do not would have been to temporarily withdraw it from the market and they didn't and that was a wake-up call to me and a reminder that even if you have a company like open AI that is a non-profit and Sam's values I think have come clear today other people can buy those companies and do what they like with them and you know maybe we have a stable set of actors now but the amount of power that these systems have to shape our views and our lives is really really significant and that doesn't even get into the risk that someone might repurpose them deliberately for all kinds of bad purposes and so in the middle of February I stopped writing much about technical issues in AI which is most of what I've written about for the last decade and said I need to work on policy this is frightening and Sam I want to give you an opportunity it's my sort of last a question or so um do don't you have concerns about I mean you you I I graduated from Stanford the the I know so many of the players in the valley uh from vcpill folks Angel folks to a lot of founders of companies that we all know do you have some concern about about a few players with with extraordinary resources and power power to influence Washington I mean I I see us I love I'm a big believer in the free market but the reason why I walk into a bodega and a Twinkie is cheaper than an apple or a Happy Meal costs less than a bucket of salad is because of the way the government tips the scales to pick winners and losers so the free market is is is not what it should be when you have large corporate power that can even influence the game here do you have some concerns about that in this in this next era of technological innovation yeah I mean again that's that's so much of why we started openai we have huge concerns about that uh I think it's important to democratize the inputs to these systems the values that we're going to align to um and I think it's also important to give people wide use of these tools when we started the API strategy uh which is a big part of how we make our systems available for anyone to use there was a huge amount of skepticism over that and it does come with challenges that's for sure but we think putting this in the hands of a lot of people and not in the hands of a few companies uh is really quite important and we are seeing the resultant Innovation boom from that um but but it is absolutely true that the number of companies that can train the true Frontier models is going to be small just because of the resources required and so I think there needs to be incredible scrutiny on us and our competitors uh I think there is a rich and exciting industry happening of incredibly good research and new startups that are not just using our models but creating their own and I think it's important to make sure that whatever regulatory stuff happens whatever new agencies may or may not happen we we preserve that fire because that's critical I'm a big believer in the democratizing potential of Technology but I've seen the promise of that fail time and time again uh where people say oh this is going to have a big democratizing force my team works on a lot of issues about the reinforcing of of of bias through algorithms the failure to advertise certain opportunities in certain zip codes um but you seem to be saying and I heard this with web3 that this is going to be diefired decentralized Finance all these things are going to happen but this is not this seems to me not even to offer that promise because the people who are designing these it takes so much power energy resources are you saying that this that my dreams of Technology further democratizing opportunity and more um are are possible within a technology that is ultimately I think going to be very centralized to a few players who already control so much so this point that I made about use of use of the model and building on top of it as a this is really a new platform right it is definitely important to talk about who's going to create the models I want to do that I also think it's really important to decide to whose values we're going to align these models but in terms of using the models the people that build on top of the open AI API do incredible things and it's you know people frequently comment like I can't believe you get this much technology for this little money and so what people are the companies people are building putting AI everywhere using our API which does let us put safeguards in place uh I think that's quite exciting and I think that is how it is being democracy not not how it's going to be but how it is being democratized right now there is a whole new Cambrian explosion of new businesses new products new Services happening buy lots of different companies on top of these models so I'll say chairman as I close that I have most Industries resist even reasonable regulation from seat belt laws uh to we've been talking a lot recently about rail safety um that the only way we're going to see the democratization of values I think and while there are noble companies out there is if we create rules of the road that enforce certain safety measures like we've seen with other technology thank you thanks Senator Booker uh and I I couldn't agree more that um in terms of consumer protection which I've been doing for a while participation by the industry is tremendously important and not just rhetorically but in real terms because we have a lot of industries that come before us and say oh we're all in favor of rules but not those rules those rules we don't like and it's every rule in fact that they don't like and I sense that there is a willingness to participate here that is genuine and authentic I thought about uh asking chat GPT to do a new version of don't stop thinking about tomorrow because that's what we need to be doing here and as Senator Hawley has pointed out Congress doesn't always move at the pace of technology and that may be a reason why we need a new agency but we also need to recognize the rest of the world is going to be moving as well and you've been enormously helpful in focusing us and Illuminating some of these questions and performed a great service by being here today so thank you to everyone of our Witnesses and uh I'm going to close the hearing leave the record open for one week in case anyone wants to submit anything I encourage any of you who have either manuscripts that are going to be published or observations from your companies uh to to submit them to us and we look forward to our next hearing this one is closed thank you\", metadata={'source': 'ibNCc74ni1c'})]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"You have {len(data)} document\")\n",
        "print(f\"You have {len(data[0].page_content)} characters in that document\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSuOlEIji44N",
        "outputId": "7d3ec087-dd16-45b5-8669-8f730812a4f8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You have 1 document\n",
            "You have 190661 characters in that document\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insert in Vector Store"
      ],
      "metadata": {
        "id": "ujCKMQCgikfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitter\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "# The embedding engine that will convert our text to vectors\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "# The vectorstore we'll be using\n",
        "from langchain.vectorstores import FAISS"
      ],
      "metadata": {
        "id": "uvmqJjy4fvFK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split in chunks"
      ],
      "metadata": {
        "id": "xS7fzgk3momJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=400)\n",
        "docs = text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "ZRIaUtKml8HZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the total number of characters so we can see the average later\n",
        "num_total_characters = sum([len(x.page_content) for x in docs])\n",
        "\n",
        "print(f\"Now you have {len(docs)} documents that have an average of {num_total_characters / len(docs):,.0f} characters (smaller pieces)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJCdPsYAmCeB",
        "outputId": "77ce5067-ae70-493f-8455-8570e3c1acd1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now you have 74 documents that have an average of 2,969 characters (smaller pieces)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gen Embeddings and ingest in Vector Store"
      ],
      "metadata": {
        "id": "LzBzLFQLnalI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get your embeddings engine ready\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# Embed your documents and combine with the raw text in a pseudo db. Note: This will make an API call to OpenAI\n",
        "docsearch = FAISS.from_documents(docs, embeddings)"
      ],
      "metadata": {
        "id": "8eXoM4L_m-oh"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set retriver configs"
      ],
      "metadata": {
        "id": "mnScofFxsgFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = docsearch.as_retriever()\n",
        "retriever.search_kwargs['distance_metric'] = 'cos'\n",
        "retriever.search_kwargs['k'] = 4"
      ],
      "metadata": {
        "id": "cfXAWt6SqrdA"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create your retrieval engine"
      ],
      "metadata": {
        "id": "MmQuvcX8n0tz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chat Models are cheaper"
      ],
      "metadata": {
        "id": "dr4IWczqAWxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "z2sco4-eo-3Q"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_model = ChatOpenAI(temperature=0, model='gpt-3.5-turbo')"
      ],
      "metadata": {
        "id": "0XHGt3-qrNs9"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The LangChain component we'll use to get the documents\n",
        "from langchain.chains import RetrievalQA\n",
        "qa = RetrievalQA.from_chain_type(llm=chat_model, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
      ],
      "metadata": {
        "id": "Ly8srJfsnzq-"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What does the author describe about Vladimir Putin?\"\n",
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "N_RAm_oAtVzG",
        "outputId": "61a3faee-3b50-495d-d4e8-52b54767293e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The author mentions that a few weeks ago, Vladimir Putin said that whoever controls AI will control the world.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try a conversational retrieval pipeline using Memory"
      ],
      "metadata": {
        "id": "XH2KyQT7aDST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
      ],
      "metadata": {
        "id": "WjgSZt1GaJHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "qa = ConversationalRetrievalChain.from_llm(chat_model, retriever=docsearch.as_retriever(), memory=memory)"
      ],
      "metadata": {
        "id": "NVyaXzsXaMEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"your question\"\n",
        "result = qa({\"question\": question})"
      ],
      "metadata": {
        "id": "jL3kH4abaL_r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}